{"name":"FACTMAC","statements":[{"name":"PROC FACTMAC","description":"The FACTMAC procedure implements the factorization machine model in SAS Viya. The flexible factorization machine model has applications in predictive modeling and recommendation (Rendle 2012). Factorization machines generalize matrix factorization, among other techniques. You can use the FACTMAC procedure to read and write data in distributed form, and to perform factorization in parallel by making full use of multicore computers or distributed computing environments.","help":"PROC FACTMAC <DATA=CAS-libref.data-table> <LEARNSTEP=number> <MAXITER=number> <NFACTORS=number> <NONNEGATIVE> <NOPRINT> <NTHREADS=number-of-threads> <OUTMODEL=data-set> <SEED=random-seed>;     \n\tAUTOTUNE <EVALHISTORY=<ALL | LOG | NONE>... > <FRACTION=number> <KFOLD=number> ...;\n    \n\tCODE <FILE=filename> ;\n    \n\tID variables;\n    \n\tINPUT <LEVEL=<NOMINAL>> ;\n    \n\tOUTPUT <COPYVAR=variable | COPYVARS=(variables)> <OUT=CAS-libref.data-table> ;\n    \n\tSAVESTATE <RSTORE=CAS-libref.data-table> ;\n    \n\tTARGET <LEVEL=<INTERVAL>> ;\n","arguments":[{"name":"DATA=","optional":true,"description":"Names the input data table for PROC FACTMAC to use. CAS-libref.data-table is a two-level name, where","help":"DATA=*CAS-libref.data-table*","type":"dataSet"},{"name":"LEARNSTEP=","optional":true,"description":"Specifies the learning step size for the stochastic gradient descent (SGD) algorithm, where number is a positive real number. The learning step size controls the amount by which the factors are updated at each iteration.","help":"LEARNSTEP=*number*","type":"value"},{"name":"MAXITER=","optional":true,"description":"Specifies the maximum number of iterations for the algorithm to perform, where number is an integer greater than or equal to 1. In each iteration of the SGD method, the factors are recomputed.","help":"MAXITER=*number*","type":"value"},{"name":"NFACTORS=","optional":true,"description":"Specifies the number of factors to estimate for the model, where number is an integer greater than or equal to 1.","help":"NFACTORS=*number*","type":"value"},{"name":"NONNEGATIVE","optional":true,"description":"Performs nonnegative factorization, in which the estimated factors are greater than or equal to 0 and the estimated biases are 0.","type":"standalone"},{"name":"NOPRINT","optional":true,"description":"Suppresses ODS output.","type":"standalone"},{"name":"NTHREADS=","optional":true,"description":"Specifies the number of threads to use for the computation, where number-of-threads can be from 1 to 64, inclusive. The default value is the maximum number of available threads per computer.","help":"NTHREADS=*number-of-threads*","type":"value"},{"name":"OUTMODEL=","optional":true,"description":"Specifies the output model data set to contain the computed factor parameters. The output data set is stored in the Work library.","help":"OUTMODEL=*data-set*","type":"dataSet"},{"name":"SEED=","optional":true,"description":"Specifies an integer that is used to start the pseudorandom number generator. This option enables you to reproduce the same sample output, but only when NTHREADS=1. If you do not specify a seed or you specify a value less than or equal to 0, the seed is generated from reading the time of day from the computer’s clock.","help":"SEED=*random-seed*","type":"value"}]},{"name":"AUTOTUNE","description":"The AUTOTUNE statement searches for the best combination of values of the NFACTORS=, LEARNSTEP=, and MAXITER= options in the PROC FACTMAC statement. You cannot specify both the OUTPUT and AUTOTUNE statements in the same run of PROC FACTMAC.","help":"AUTOTUNE &lt;EVALHISTORY=&lt;ALL | LOG | NONE&gt;... &gt; &lt;FRACTION=number&gt; &lt;KFOLD=number&gt; ...","arguments":[{"name":"EVALHISTORY=","optional":true,"description":"Specifies how to report the evaluation history of the tuner.","help":"EVALHISTORY=ALL | LOG | NONE | TABLE","type":"choice","arguments":[{"name":"ALL","description":"Reports each evaluation in the log and creates the EvaluationHistory ODS table.","type":"standalone"},{"name":"LOG","description":"Prints the following information to the log for each evaluation: evaluation number, objective value, best objective value up to that point, evaluation time, and elapsed time since the beginning of the tuning process.","type":"standalone"},{"name":"NONE","description":"Suppresses reporting of evaluations in the log and does not create the EvaluationHistory ODS table.","type":"standalone"},{"name":"TABLE","description":"Creates the EvaluationHistory ODS table, which contains all evaluated points. The table contains columns for the evaluation number, all tuning parameters, and the objective function value.","type":"standalone"}]},{"name":"FRACTION=","optional":true,"description":"Specifies the fraction of all data to be used for validation, where number must be between 0.01 and 0.99, inclusive. If you specify this option, the tuner uses a single partition validation for finding the objective value (validation error estimate). This option might not be advisable for small or unbalanced data tables where the random assignment of the validation subset might not provide a good estimate of error. For large, balanced data tables, a single validation partition is usually sufficient for estimating error; a single partition is more efficient than cross validation in terms of the total execution time. By default, FRACTION=0.3. You cannot specify this option in combination with the KFOLD= option.","help":"FRACTION=*number*","type":"value"},{"name":"KFOLD=","optional":true,"description":"Specifies the number of partition folds in the cross validation process, where number must be between 2 and 20, inclusive. If you specify this option, the tuner uses cross validation to find the objective value. In cross validation, each model evaluation requires number of training executions (on number–1 data folds) and number of scoring executions (on 1 hold-out fold). Thus, the evaluation time is increased by approximately number. For small to medium data tables or for unbalanced data tables, cross validation provides on average a better representation of error across the entire data table (a better generalization error). By default, KFOLD=5. You cannot specify this option in combination with the FRACTION= option.","help":"KFOLD=*number*","type":"value"},{"name":"MAXEVALS=","optional":true,"description":"Specifies the maximum number of configuration evaluations allowed for the tuner, where number must be an integer greater than or equal to 3. When the number of evaluations is reached, the tuner terminates the search and returns the results. To produce a single objective function value (validation error estimate), each configuration evaluation requires either a single model training and scoring execution on a validation partition, or a number of training and scoring executions equal to the value of the KFOLD= option for cross validation. The MAXEVALS= option might lead to termination before the value of the MAXITER= option or the MAXTIME= option is reached. By default, MAXEVALS=50.","help":"MAXEVALS=*number*","type":"value"},{"name":"MAXITER=","optional":true,"description":"Specifies the maximum number of iterations of the optimization tuner, where number must be greater than or equal to 1. Each iteration normally involves a number of objective evaluations up to the value of the POPSIZE= option. The MAXITER= option might lead to termination before the value of the MAXEVALS= option or the MAXTIME= option is reached. By default, MAXITER=5.","help":"MAXITER=*number*","type":"value"},{"name":"MAXTIME=","optional":true,"description":"Specifies the maximum time (in seconds) allowed for the tuner, where number must be greater than or equal to 1. When this value is reached, the tuner terminates the search and returns results. The actual run time for optimization might be longer because it includes the remaining time needed to finish the current evaluation. For long-running model training (large data tables), the actual run time might significantly exceed number. The MAXTIME= option might lead to termination before the value of the MAXEVALS= option or the MAXITER= option is reached. By default, MAXTIME=36000.","help":"MAXTIME=*number*","type":"value"},{"name":"NPARALLEL=","optional":true,"description":"Specifies the number of evaluations to be performed in parallel, where number must be greater than or equal to 0. When SEARCHMETHOD=GA is specified, the value of number is equal to the value of the POPSIZE= option minus one. When SEARCHMETHOD=LHS or SEARCHMETHOD=RANDOM is specified, the value of number is equal to the value of SAMPLESIZE= option.","help":"NPARALLEL=*number*","type":"value"},{"name":"NSUBSESSIONWORKERS=","optional":true,"description":"Specifies the number of workers to use in parallel subsessions. When evaluating alternative configurations in parallel, a number of subsessions is created by the tuner, with each subsession potentially using multiple workers. The number of workers used in a parallel subsession is determined by using either NSUBSESSIONWORKERS=number, if specified, or determined automatically based upon the size of the data.","help":"NSUBSESSIONWORKERS=*number*","type":"value"},{"name":"OBJECTIVE=","optional":true,"description":"Specifies which measure of model performance the tuner uses as the objective function.","help":"OBJECTIVE=ASE | AUC | F05 | F1 | GAMMA | GINI | KS | MAE | MCE | MCLL | MISC | MSE | MSLE | RASE | RMAE | RMSLE | TAU*function*","type":"value","arguments":[{"name":"ASE","description":"Uses average squared error as the objective function.","type":"standalone"},{"name":"AUC","description":"Uses area under the curve as the objective function (nominal type only).","type":"standalone"},{"name":"F05","description":"Uses the F0.5 coefficient as the objective function (nominal type only).","type":"standalone"},{"name":"F1","description":"Uses the F1 coefficient as the objective function (nominal type only).","type":"standalone"},{"name":"GAMMA","description":"Uses the gamma coefficient as the objective function (nominal type only).","type":"standalone"},{"name":"GINI","description":"Uses the Gini coefficient as the objective function (nominal type only).","type":"standalone"},{"name":"KS","description":"Uses the Kolmogorov-Smirnov coefficient as the objective function (nominal type only).","type":"standalone"},{"name":"MAE","description":"Uses the mean absolute error as the objective function (interval type only).","type":"standalone"},{"name":"MCE","description":"Uses the misclassification rate as the objective function (nominal type only).","type":"standalone"},{"name":"MCLL","description":"Uses the multiclass log loss as the objective function (nominal type only).","type":"standalone"},{"name":"MISC","description":"Uses the misclassification error percentage as the objective function (nominal type only).","type":"standalone"},{"name":"MSE","description":"Uses the mean squared error as the objective function (interval type only).","type":"standalone"},{"name":"MSLE","description":"Uses the mean squared logarithmic error as the objective function (interval type only).","type":"standalone"},{"name":"RASE","description":"Uses the root average squared error as the objective function.","type":"standalone"},{"name":"RMAE","description":"Uses the root mean absolute error as the objective function (interval type only).","type":"standalone"},{"name":"RMSLE","description":"Uses the root mean squared logarithmic error as the objective function (interval type only).","type":"standalone"},{"name":"TAU","description":"Uses the tau coefficient as the objective function (nominal type only).","type":"standalone"}]},{"name":"POPSIZE=","optional":true,"description":"Specifies the maximum number of evaluations in one iteration (population), where number must be greater than or equal to 1. In some cases, the tuner algorithm might generate a number of new configurations smaller than number. By default, POPSIZE=10.","help":"POPSIZE=*number*","type":"value"},{"name":"SAMPLESIZE=","optional":true,"description":"Specifies the total number of evaluations, where number must be greater than or equal to 1. You can specify this option when SEARCHMETHOD=RANDOM or SEARCHMETHOD=LHS. This option is ignored when SEARCHMETHOD=GA.","help":"SAMPLESIZE=*number*","type":"value"},{"name":"SEARCHMETHOD=","optional":true,"description":"Specifies the search method to use for tuning.","help":"SEARCHMETHOD=BAYESIAN | GA | LHS | RANDOM","type":"choice","arguments":[{"name":"BAYESIAN","description":"Builds a Kriging surrogate model to approximate the objective value, and uses this surrogate model for generating new alternative configurations at each iteration.","type":"standalone"},{"name":"GA","description":"Uses an initial Latin hypercube sample that seeds a genetic algorithm to generate a new population of alternative configurations at each iteration.","type":"standalone"},{"name":"LHS","description":"Uses a Latin hypercube to generate a single sample of configurations that is uniform in each tuning parameter, but random in combinations.","type":"standalone"},{"name":"RANDOM","description":"Generates a single sample of purely random configurations.","type":"standalone"}]},{"name":"TARGETEVENT=","optional":true,"description":"Specifies the target event to use for calculating the selected objective function. This option is ignored when the value of the OBJECTIVE= option is not AUC, F1, F05, GINI, GAMMA, TAU, or KS.","help":"TARGETEVENT=*string*","type":"value"},{"name":"TUNINGPARAMETERS=","optional":true,"description":"Specifies which parameters to tune and which ranges to tune over. If USEPARAMETERS=STANDARD, this option is ignored.","help":"TUNINGPARAMETERS=NFACTORS | LB= | UB= | VALUES= | INIT= | EXCLUDE | LEARNSTEP | MAXITER","type":"choice","arguments":[{"name":"NFACTORS","type":"standalone"},{"name":"LB=","type":"value"},{"name":"UB=","type":"value"},{"name":"VALUES=","type":"value"},{"name":"INIT=","type":"value"},{"name":"EXCLUDE","type":"standalone"},{"name":"LEARNSTEP","type":"standalone"},{"name":"MAXITER","type":"standalone"}]},{"name":"USEPARAMETERS=","optional":true,"description":"Specifies how to handle the TUNINGPARAMETERS= option.","help":"USEPARAMETERS=STANDARD | CUSTOM | COMBINED*tuning-parameter-option*","type":"value","arguments":[{"name":"STANDARD","description":"Tunes using the default bounds and initial values for all parameters.","type":"standalone"},{"name":"CUSTOM","description":"Tunes only the parameters that are specified in the TUNINGPARAMETERS= option.","type":"standalone"},{"name":"COMBINED","description":"Tunes the parameters that are specified in the TUNINGPARAMETERS= option and uses default bounds and initial values to tune all other parameters.","type":"standalone"}]}]},{"name":"CODE","description":"The CODE statement generates SAS DATA step code that mimics the computations that are performed. The generated SAS DATA step code can be used for scoring new observations. Only one CODE statement is processed. If you specify multiple CODE statements, only the first one is used. The CODE statement is optional. If you do not include a CODE statement, no score code is generated.","help":"CODE &lt;FILE=filename&gt; ","arguments":[{"name":"FILE=","optional":true,"description":"Specifies the filename of the file to write the SAS score code to.","help":"FILE=*filename*","type":"value"}]},{"name":"ID","description":"The ID statement lists one or more variables that are to be copied from the input data table to the output data tables that are specified in the OUT= option in the OUTPUT statement and the RSTORE= option in the SAVESTATE statement.","help":"ID variables"},{"name":"INPUT","description":"The INPUT statement specifies the names of the variables to be used in the factorization. It names one or more input variables that use common options. If you want to use different options for different variables, you can specify multiple INPUT statements.","help":"INPUT &lt;LEVEL=&lt;NOMINAL&gt;&gt; ","arguments":[{"name":"LEVEL=","optional":true,"description":"Specifies the level of measurement of the variables.","help":"LEVEL=NOMINAL*NOMINAL*","type":"value","arguments":[{"name":"NOMINAL","description":"Specifies NOMINAL input variables.","type":"standalone"}]}]},{"name":"OUTPUT","description":"The OUTPUT statement creates an output data table to contain the results of the procedure run.","help":"OUTPUT &lt;COPYVAR=variable | COPYVARS=(variables)&gt; &lt;OUT=CAS-libref.data-table&gt; ","arguments":[{"name":"COPYVAR=","optional":true,"aliases":["COPYVARS="],"description":"Lists one or more variables from the input data table to be transferred to the output data table.","type":"value"},{"name":"OUT=","optional":true,"description":"Names the output data table for PROC FACTMAC to use. CAS-libref.data-table is a two-level name, where","help":"OUT=*CAS-libref.data-table*","type":"dataSet"}]},{"name":"SAVESTATE","description":"The SAVESTATE statement creates an analytic store for the model and saves it as a binary object in a data table. You can use the analytic store in the ASTORE procedure to score new data.","help":"SAVESTATE &lt;RSTORE=CAS-libref.data-table&gt; ","arguments":[{"name":"RSTORE=","optional":true,"description":"Specifies a data table in which to save the analytic store for the model. CAS-libref.data-table is a two-level name, where CAS-libref refers to the caslib and session identifier, and data-table specifies the name of the output data table.","help":"RSTORE=*CAS-libref.data-table*","type":"dataSet"}]},{"name":"TARGET","description":"The TARGET statement names the target variable whose values PROC FACTMAC predicts. The target must be interval and must be different from the variables in the INPUT statement.","help":"TARGET &lt;LEVEL=&lt;INTERVAL&gt;&gt; ","arguments":[{"name":"LEVEL=","optional":true,"description":"Specifies the level of measurement of the variables.","help":"LEVEL=INTERVAL*INTERVAL*","type":"value","arguments":[{"name":"INTERVAL","description":"Specifies INTERVAL target variables.","type":"standalone"}]}]}],"supportSiteInformation":{"docsetId":"casml","docsetVersion":"v_032","docsetTargetFile":"casml_factmac_toc.htm"}}