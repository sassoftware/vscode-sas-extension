{"name":"FOREST","statements":[{"name":"PROC FOREST","description":"The FOREST procedure creates a predictive model called a forest (which consists of several decision trees) in SAS Viya. A predictive model defines a relationship between input variables and a target variable. The purpose of a predictive model is to predict a target value from inputs. The FOREST procedure trains the model; that is, it creates the model by using training data in which the target values are known. The model can then be applied to observations in which the target is unknown. If the predictions fit the new data well, the model is said to generalize well. Good generalization is the primary goal for predictive tasks. A predictive model might fit the training data well but generalize poorly.","help":"PROC FOREST <options>;                 \n\tAUTOTUNE <options>;                 \n\tCODE <options>;                 \n\tCROSSVALIDATION <options>;                 \n\tFREQ  variable;                 \n\tGROW criterion;                 \n\tID variables;                 \n\tINPUT  variables </ LEVEL={INTERVAL | NOMINAL}>;                 \n\tMITIGATEBIAS  SENSITIVEVAR=variable PREDICTEDVARS=(variable-names) PREDICTEDEVENTS=\"event-list\" <options>;                 \n\tOUTPUT  OUT=libref.data-table<option>;                 \n\tPARTITION  partition-option;                 \n\tSAVESTATE  RSTORE=libref.data-table;                 \n\tTARGET  variable </ LEVEL={NOMINAL | INTERVAL}>;                 \n\tVIICODE <options>;                 \n\tWEIGHT  variable;                 ","arguments":[{"name":"APPLYROWORDER","optional":true,"description":"uses a data distribution and row order as determined by a previous partition action call","type":"standalone"},{"name":"ASSIGNMISSING=","optional":true,"description":"specifies how PROC FOREST creates a default splitting rule that is used to handle missing values and unknown levels","help":"ASSIGNMISSING=NONE | MACSMALL | USEINSEARCH","type":"choice"},{"name":"BINMETHOD=","optional":true,"description":"specifies how to bin interval input variables prior to growing the forest model","help":"BINMETHOD=BUCKET | QUANTILE","type":"choice"},{"name":"DATA=","optional":true,"description":"names the input data table for PROC FOREST to use","help":"DATA=*libref.data-table*","type":"dataSet"},{"name":"INBAGFRACTION=","optional":true,"aliases":["BOOTSTRAP="],"description":"specifies the fraction of the random bootstrap sample of the training data to be used for growing each tree in the forest, where number is a value between 0 and 1","help":"INBAGFRACTION=*number*","type":"value"},{"name":"INMODEL=","optional":true,"description":"specifies the data table that you have previously saved as a forest model by using the OUTMODEL= option in a previous run of PROC FOREST","help":"INMODEL=&lt;*libref.*&gt;*data-table*","type":"dataSet"},{"name":"ISOLATION","optional":true,"description":"creates an isolation forest for anomaly detection instead of creating a forest for target prediction","help":"ISOLATION &lt;(SAMPLEN=*number*)&gt;","type":"standaloneOrValue","arguments":[{"name":"SAMPLEN=","description":"specifies the number of observations, sampled without replacement, to use in each tree of the isolation forest","help":"SAMPLEN=*number*","type":"value"}]},{"name":"LOH=","optional":true,"description":"specifies a number of variables (L) that are preselected to consider for candidate splits for each node","help":"LOH=*L*","type":"value"},{"name":"MAXBRANCH=","optional":true,"description":"specifies the maximum number of children per node in the tree","help":"MAXBRANCH=*b*","type":"value"},{"name":"MAXDEPTH=","optional":true,"description":"specifies the maximum depth of the tree to be grown","help":"MAXDEPTH=*number*","type":"value"},{"name":"MINLEAFSIZE=","optional":true,"aliases":["LEAFSIZE="],"description":"specifies the minimum number of observations that each child of a split must contain in the training data table in order for the split to be considered","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"MINUSEINSEARCH=","optional":true,"description":"specifies a threshold for using missing values in the split search when ASSIGNMISSING=USEINSEARCH","help":"MINUSEINSEARCH=*number*","type":"value"},{"name":"NOMSEARCH","optional":true,"description":"specifies search methods for splitting on a nominal variable","help":"NOMSEARCH(*suboption*...)","type":"value","arguments":[{"name":"MAXCATEGORIES=","description":"specifies the maximum number of categories to use in a splitting rule","help":"MAXCATEGORIES=*number*","type":"value"},{"name":"SHRINKAGE=","description":"specifies how much weight to give the average gradient when you combine it with the average gradient within a category","help":"SHRINKAGE=*number*","type":"value"},{"name":"SORT=","description":"specifies the minimum cardinality in the node of the nominal variable for using the sort method","help":"SORT=*number*","type":"value"}]},{"name":"NOPRINT","optional":true,"description":"suppresses ODS output","type":"standalone"},{"name":"NTHREADS=","optional":true,"description":"specifies the number of threads to use in the computation","help":"NTHREADS=*number-of-threads*","type":"value"},{"name":"NTREES=","optional":true,"description":"specifies the number of trees to grow in the forest model","help":"NTREES=*number*","type":"value"},{"name":"NUMBIN=","optional":true,"aliases":["NBINS="],"description":"specifies the number of bins to use for binning the interval input variables","help":"NUMBIN=*number*","type":"value"},{"name":"OUTMODEL=","optional":true,"description":"specifies the data table to which to save the forest model","help":"OUTMODEL=&lt;*libref.*&gt;*data-table*","type":"dataSet"},{"name":"PRINTTARGET","optional":true,"description":"outputs tables that indicate generated columns in the OUT= table from the OUTPUT statement","type":"standalone"},{"name":"RBAIMP","optional":true,"description":"creates a variable importance table by using random branch assignment (RBA)","type":"standalone"},{"name":"SEED=","optional":true,"description":"specifies the initial seed for random number generation that is used in both selecting out-of-bag observations for the trees and selecting the subset of variables to determine splits","help":"SEED=*number*","type":"value"},{"name":"VARS_TO_TRY=","optional":true,"aliases":["M="],"description":"specifies the number of input variables to consider splitting on in a node, where m ranges from 1 to the number of input variables","help":"VARS_TO_TRY=*m*","type":"value"},{"name":"VII=","optional":true,"aliases":["INTERACTIONIMP="],"description":"calculates the variable interaction importance, which is described in the section {forest.details_intimp}","help":"VII=2 | 3","type":"choice"},{"name":"VOTE=","optional":true,"description":"specifies how to calculate the predicted probability of the target levels for a nominal target","help":"VOTE=MAJORITY | PROBABILITY","type":"choice"}]},{"name":"AUTOTUNE","description":"searches for the best combination of values of the INBAGFRACTION=, MAXDEPTH=, MINLEAFSIZE=, NUMBIN=, NTREES=, and VARS_TO_TRY= options in the PROC FOREST statement","help":"AUTOTUNE &lt;options&gt;;                                              ","arguments":[{"name":"TUNINGPARAMETERS=","optional":true,"aliases":["TUNEPARMS="],"description":"specifies which parameters to tune and which ranges to tune over","help":"TUNINGPARAMETERS=(*suboption* |...| &lt;*suboption*&gt;)","type":"value","arguments":[{"name":"INBAGFRACTION","description":"specifies information about the fraction of the training data to use for each bagged tree while tuning the forest model","help":"INBAGFRACTION (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum fraction of training data to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum fraction of training data to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of fractions of training data to consider during tuning, where value-list is a space-separated list of numbers greater than 0 and less than or equal to 1","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial fraction of training data for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the fraction of the training data to use for each bagged tree from the tuning process","type":"standalone"}]},{"name":"MAXDEPTH","description":"specifies information about the maximum depth to which to grow the trees in the forest","help":"MAXDEPTH (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies a lower bound on the maximum depth to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies an upper bound on the maximum depth to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of values to consider for the maximum depth of the trees in the forest, where value-list is a space-separated list of numbers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial maximum depth of trees in the forest","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes maximum depth from the tuning process","type":"standalone"}]},{"name":"MINLEAFSIZE","description":"specifies information about tuning the leaf size option for training the decision tree","help":"MINLEAFSIZE (LB=*number* UB= *number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum leaf size value to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum leaf size value to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of leaf size values to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial leaf size for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the leaf size from the tuning process","type":"standalone"}]},{"name":"NUMBIN","description":"specifies information about the number of bins in which to bin the interval inputs while tuning the decision tree","help":"NUMBIN (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum number of bins to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum number of bins to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of numbers of bins to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial number of bins for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the number of bins from the tuning process","type":"standalone"}]},{"name":"NTREES","description":"specifies information about the number of trees in the forest to use for tuning the forest model","help":"NTREES (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum number of trees to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum number of trees to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of numbers of trees to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial number of trees for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the number of trees from the tuning process","type":"standalone"}]},{"name":"VARS_TO_TRY","description":"specifies information about the number of variables to consider at each split during tree growth while tuning the forest model","help":"VARS_TO_TRY (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum number of variables to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum number of variables to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of numbers of variables to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial number of variables for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the number of variables from the tuning process","type":"standalone"}]}]}]},{"name":"CODE","description":"writes SAS DATA step code for computing predicted values of the fitted model to a file or to a table","help":"CODE &lt;options&gt;;                                              ","arguments":[{"name":"COMMENT","optional":true,"description":"Adds comments to the generated code","type":"standalone"},{"name":"FILE=","optional":true,"description":"Names the file in which to save the generated code","type":"value"},{"name":"FORMATWIDTH=","optional":true,"description":"Specifies the numeric format width for the regression coefficients","type":"value"},{"name":"INDENTSIZE=","optional":true,"description":"Specifies the number of spaces to indent the generated code","type":"value"},{"name":"LABELID=","optional":true,"description":"Specifies a number used to construct names and labels","type":"value"},{"name":"LINESIZE=","optional":true,"description":"Specifies the line size for the generated code","type":"value"},{"name":"NOTRIM","optional":true,"description":"Compares formatted values, including blank padding","type":"standalone"},{"name":"OUT=","optional":true,"description":"Names an output table in which to save the generated code","type":"value"}]},{"name":"CROSSVALIDATION","description":"performs k-fold cross validation to find the average estimated validation error","help":"CROSSVALIDATION &lt;options&gt;;                                              ","arguments":[{"name":"KFOLD=","optional":true,"description":"specifies the number of partition folds in the cross validation process, where number is between 2 and 20, inclusive","help":"KFOLD=*number*","type":"value"},{"name":"NOPARALLEL","optional":true,"description":"specifies that k-fold cross validation not be run in parallel","type":"standalone"},{"name":"NSUBSESSIONWORKERS=","optional":true,"description":"specifies the number of worker nodes to use in parallel subsessions","help":"NSUBSESSIONWORKERS=*number*","type":"value"}]},{"name":"FREQ","description":"identifies a numeric variable in the input data table that contains the frequency of occurrence of each observation","help":"FREQ  variable;                                              "},{"name":"GROW","description":"specifies the criterion by which to split a parent node into child nodes","help":"GROW *criterion*;                                              ","arguments":[{"name":"CHAID","optional":true,"description":"for categorical predictor variables, CHAID uses the value (as specified in the ALPHA= option) of a chi-square statistic (for a classification tree) or an F statistic (for a regression tree) to merge similar levels of the predictor variable until the number of children in the proposed split reaches the number that you specify in the MAXBRANCH= option in the PROC FOREST statement","type":"standalone"},{"name":"CHISQUARE","optional":true,"description":"uses a chi-square statistic to split each variable and then uses the p-values that correspond to the resulting splits to determine the splitting variable","type":"standalone"},{"name":"ENTROPY","optional":true,"aliases":["GAIN"],"description":"uses the gain in information (decrease in entropy) to split each variable and then to determine the split","type":"standalone"},{"name":"GINI","optional":true,"description":"uses the decrease in the Gini index to split each variable and then to determine the split","type":"standalone"},{"name":"IGR","optional":true,"description":"uses the entropy metric to split each variable and then uses the information gain ratio to determine the split","type":"standalone"},{"name":"FTEST","optional":true,"description":"uses an F statistic to split each variable and then uses the resulting p-value to determine the split variable","type":"standalone"},{"name":"RSS","optional":true,"aliases":["VARIANCE"],"description":"uses the change in response variance to split each variable and then to determine the split","type":"standalone"}]},{"name":"ID","description":"lists one or more variables that are to be copied from the input data table to the output data tables that are specified in the OUT= option in the OUTPUT statement and the RSTORE= option in the SAVESTATE statement","help":"ID *variables*;                                              "},{"name":"INPUT","description":"names input variables that share a common option","help":"INPUT  variables &lt;/ LEVEL={INTERVAL | NOMINAL}&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the level of measurement of the variables","help":"LEVEL={INTERVAL | NOMINAL}","type":"choice"}]},{"name":"MITIGATEBIAS","description":"enables PROC FOREST to iteratively train a model while minimizing the bias metric that you specify","help":"MITIGATEBIAS  SENSITIVEVAR=*variable* PREDICTEDVARS=(*variable-names*) PREDICTEDEVENTS=\"*event-list*\" &lt;options&gt;;                                              ","arguments":[{"name":"PREDICTEDEVENTS=","optional":true,"aliases":["PEVENTS="],"description":"specifies the events that correspond to each variable in the PREDICTEDVARS= option","help":"PREDICTEDEVENTS=\"*event-list*\"","type":"value"},{"name":"PREDICTEDVARS=","optional":true,"aliases":["PVARS="],"description":"specifies the names of the variables that contain the posterior probability for each level in model prediction that corresponds to the response (target) variable","help":"PREDICTEDVARS=(*variable-names*)","type":"value"},{"name":"SENSITIVEVAR=","optional":true,"description":"specifies the sensitive variable to use in order to reduce the value of the bias measurement that you specify in the BIASMETRIC= option","help":"SENSITIVEVAR=*variable*","type":"value"},{"name":"BIASMETRIC=","optional":true,"description":"specifies the type of bias measurement","help":"BIASMETRIC=*bias-metric*","type":"value"},{"name":"BOUND=","optional":true,"description":"specifies the bound value for the exponentiated gradient reduction algorithm","help":"BOUND=*number*","type":"value"},{"name":"DELIMITER=","optional":true,"aliases":["DLM="],"description":"specifies the delimiter to be used to separate events that you specify in the PREDICTEDEVENTS= option","help":"DELIMITER=\"*character*\"","type":"value"},{"name":"LEARNINGRATE=","optional":true,"description":"specifies the step size to use in updating the exponentiated gradient reduction algorithm","help":"LEARNINGRATE=*number*","type":"value"},{"name":"LOGLEVEL=","optional":true,"description":"specifies the level of log information to print","help":"LOGLEVEL=0 | 1 | 2","type":"choice"},{"name":"MAXITER=","optional":true,"description":"specifies the maximum number of iterations to run the exponentiated gradient reduction algorithm","help":"MAXITER=*number*","type":"value"},{"name":"SEED=","optional":true,"description":"specifies the seed for the pseudorandom number generator","help":"SEED=*number*","type":"value"},{"name":"TARGETEVENT=","optional":true,"description":"specifies the formatted value of the response (target) variable that represents the event of interest","help":"TARGETEVENT=\"*event*\"","type":"value"},{"name":"TOLERANCE=","optional":true,"description":"specifies the parity constraint violation tolerance","help":"TOLERANCE=*number*","type":"value"},{"name":"TUNEBOUND","optional":true,"description":"specifies that the bound value must be tuned","type":"standalone"}]},{"name":"OUTPUT","description":"creates an output data table that contains the results of PROC FOREST","help":"OUTPUT  OUT=*libref.data-table*&lt;option&gt;;                                              ","arguments":[{"name":"OUT=","optional":true,"description":"names the output data table for PROC FOREST to use","help":"OUT=*libref.data-table*","type":"dataSet"},{"name":"COPYVAR=","optional":true,"aliases":["COPYVARS="],"description":"lists one or more variables from the input data table to be transferred to the output data table","help":"COPYVAR={*variable*}","type":"value"},{"name":"ROLE","optional":true,"description":"generates a numeric variable that indicates the role played by each observation in fitting the model","help":"ROLE&lt;={*name*}&gt;","type":"standaloneOrValue"}]},{"name":"PARTITION","description":"specifies how observations in the input data set are logically partitioned into disjoint subsets for model training, validation, and testing","help":"PARTITION  partition-option;                                              ","arguments":[{"name":"FRACTION","optional":true,"description":"randomly assigns specified proportions of the observations in the input data table to the roles","help":"FRACTION(&lt;TEST=*fraction*&gt; &lt;VALIDATE=*fraction*&gt; &lt;SEED=*number*&gt;)","type":"standaloneOrValue"},{"name":"ROLE=","optional":true,"aliases":["ROLEVAR="],"description":"names the variable in the input data table whose values are used to assign roles to each observation","help":"ROLE={*variable* (&lt;TEST=*'value'*&gt; &lt;TRAIN=*'value'*&gt; &lt;VALIDATE=*'value'*&gt;) }","type":"value"}]},{"name":"SAVESTATE","description":"creates an analytic store for the model and saves it as a binary object in a data table","help":"SAVESTATE  RSTORE=*libref.data-table*;                                              ","arguments":[{"name":"RSTORE=","optional":true,"description":"specifies a data table in which to save the analytic store for the model","help":"RSTORE=*libref.data-table*","type":"dataSet"}]},{"name":"TARGET","description":"names the variable whose values PROC FOREST tries to predict","help":"TARGET  variable &lt;/ LEVEL={NOMINAL | INTERVAL}&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the level of measurement","help":"LEVEL={NOMINAL | INTERVAL}","type":"choice"}]},{"name":"VIICODE","description":"writes SAS DATA step code to a file or to a catalog entry","help":"VIICODE &lt;options&gt;;                                              ","arguments":[{"name":"ADD","optional":true,"description":"requests that the newly created variables be of the form V + W","type":"standalone"},{"name":"LIMIT=","optional":true,"description":"specifies the maximum number of new variables to create","help":"LIMIT=*number*","type":"value"},{"name":"MISS","optional":true,"description":"requests that the generated code handle missing values","type":"standalone"},{"name":"MULTIPLY","optional":true,"description":"requests that the newly created variables be of the form V W","type":"standalone"},{"name":"SUBTRACT","optional":true,"description":"requests that the newly created variables be of the form V - W","type":"standalone"},{"name":"THRESHOLD=","optional":true,"description":"requests that interactions with an importance less than number times the maximum interaction importance be ignored, where number must be between 0 and 1","help":"THRESHOLD=*number*","type":"value"}]},{"name":"WEIGHT","description":"variable is used to weight each observation to perform a weighted analysis of the data","help":"WEIGHT  variable;                                              "}],"supportSiteInformation":{"docsetId":"casml","docsetVersion":"latest","docsetTargetFile":"casml_forest_toc.htm"}}