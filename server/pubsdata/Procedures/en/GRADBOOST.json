{"name":"GRADBOOST","statements":[{"name":"PROC GRADBOOST","description":"The GRADBOOST procedure creates a predictive model called a gradient boosting model in SAS Viya. A gradient boosting model consists of multiple decision trees. A predictive model defines a relationship between input variables and a target variable. The purpose of a predictive model is to predict a target value from inputs. The GRADBOOST procedure creates the model by using training data in which the target values are known. The model can then be applied to observations in which the target is unknown. If the predictions fit the new data well, the model is said to generalize well. Good generalization is the primary goal of predictive tasks. A predictive model might fit the training data well but generalize poorly.","help":"PROC GRADBOOST <options>;                 \n\tAUTOTUNE <options>;                 \n\tCODE <options>;                 \n\tCROSSVALIDATION <options>;                 \n\tFREQ  variable;                 \n\tID variables;                 \n\tINPUT  variables </ options>;                 \n\tOUTPUT  OUT=libref.data-table<option>;                 \n\tPARTITION  partition-option;                 \n\tSAVESTATE  RSTORE=libref.data-table;                 \n\tTARGET  variable </ LEVEL={NOMINAL | INTERVAL}>;                 \n\tMITIGATEBIAS  SENSITIVEVAR=variable PREDICTEDVARS=(variable-names) PREDICTEDEVENTS=\"event-list\" <options>;                 \n\tTRANSFERLEARN  variable </ options>;                 \n\tVIICODE <options>;                 \n\tWEIGHT  variable;                 ","arguments":[{"name":"ADDTREES","optional":true,"description":"adds trees to an already generated gradient boosting model, which is specified in the INMODEL= option","type":"standalone"},{"name":"APPLYROWORDER","optional":true,"description":"uses a data distribution and row order as determined by a previous partition action call","type":"standalone"},{"name":"ASSIGNMISSING=","optional":true,"description":"specifies how to handle missing values during training and creates a splitting rule to handle missing values and unknown levels during scoring","help":"ASSIGNMISSING=NONE | MACSMALL | USEINSEARCH","type":"choice"},{"name":"BINMETHOD=","optional":true,"description":"specifies how to bin interval input variables prior to growing the gradient boosting model","help":"BINMETHOD=BUCKET | QUANTILE","type":"choice"},{"name":"DATA=","optional":true,"description":"names the input data table for PROC GRADBOOST to use","help":"DATA=*libref.data-table*","type":"dataSet"},{"name":"DISTRIBUTION=","optional":true,"description":"specifies the distribution of the objective function","help":"DISTRIBUTION=BINARY | GAUSSIAN | MULTINOMIAL | POISSON | TWEEDIE(POWER=*p*)","type":"value"},{"name":"EARLYSTOP","optional":true,"description":"specifies options for stopping the gradient boosting model training early","help":"EARLYSTOP(*suboption*...)","type":"value","arguments":[{"name":"METRIC=","description":"specifies whether to use the misclassification rate or the log-loss prediction error in early stopping for a binary or nominal target","help":"METRIC=MCR | LOGLOSS","type":"choice"},{"name":"MINIMUM=","description":"specifies whether the stagnation approach should count iterations starting from the iteration that has the smallest error","help":"MINIMUM=NO | YES","type":"choice"},{"name":"STAGNATION=","description":"specifies the number of iterations in the gradient boosting model to consider for early stopping, where number must be a nonnegative integer","help":"STAGNATION=*number*","type":"value"},{"name":"THRESHOLD=","description":"specifies the threshold value that stops training when the error equals or exceeds it","type":"value"},{"name":"THRESHOLDITER=","description":"specifies the minimum number of training iterations to run before the threshold approach is invoked","help":"THRESHOLDITER=*T*","type":"value"},{"name":"TOLERANCE=","description":"specifies the number to be used as the tolerance for the stagnation approach to early stopping, where number must be nonnegative","help":"TOLERANCE=*number*","type":"value"}]},{"name":"INMODEL=","optional":true,"description":"specifies the data table that you previously saved as a gradient boosting model by using the OUTMODEL= option in a previous run of PROC GRADBOOST","help":"INMODEL=*libref.**data-table*","type":"dataSet"},{"name":"LASSO=","optional":true,"aliases":["L1="],"description":"specifies the L1 norm regularization parameter, where number must be nonnegative","help":"LASSO=*number*","type":"value"},{"name":"LEARNINGRATE=","optional":true,"description":"specifies the learning rate for the gradient boosting algorithm, where number must be between 0 and 1, inclusive","help":"LEARNINGRATE=*number*","type":"value"},{"name":"MAXBRANCH=","optional":true,"description":"specifies the maximum number of children per node in the tree","help":"MAXBRANCH=*b*","type":"value"},{"name":"MAXDEPTH=","optional":true,"description":"specifies the maximum depth of the tree to be grown","help":"MAXDEPTH=*number*","type":"value"},{"name":"MINLEAFSIZE=","optional":true,"aliases":["LEAFSIZE="],"description":"specifies the minimum number of observations that each child of a split must contain in the training data table in order for the split to be considered","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"MINUSEINSEARCH=","optional":true,"description":"specifies a threshold for using missing values in the split search when ASSIGNMISSING=USEINSEARCH","help":"MINUSEINSEARCH=*number*","type":"value"},{"name":"NOMSEARCH","optional":true,"description":"specifies search methods for splitting on a nominal variable","help":"NOMSEARCH(*suboption*...)","type":"value","arguments":[{"name":"MAXCATEGORIES=","description":"specifies the maximum number of categories to use in a splitting rule","help":"MAXCATEGORIES=*number*","type":"value"},{"name":"SHRINKAGE=","description":"specifies how much weight to give the average gradient when you combine it with the average gradient within a category","help":"SHRINKAGE=*number*","type":"value"},{"name":"SORT=","description":"specifies the minimum cardinality in the node of the nominal variable for using the sort method","help":"SORT=*number*","type":"value"}]},{"name":"NOPRINT","optional":true,"description":"suppresses ODS output","type":"standalone"},{"name":"NTHREADS=","optional":true,"description":"The gradient boosting algorithm automatically determines the default value on the basis of the properties of the training data, model, and hardware that you use","help":"NTHREADS=*number*","type":"value"},{"name":"NTREES=","optional":true,"description":"specifies the number of trees to grow in the gradient boosting model","help":"NTREES=*number*","type":"value"},{"name":"NUMBIN=","optional":true,"aliases":["NBINS="],"description":"specifies the number of bins to use for binning the interval input variables","help":"NUMBIN=*number*","type":"value"},{"name":"OFFSET=","optional":true,"description":"specifies an offset variable to be used with DISTRIBUTION=POISSON or TWEEDIE","help":"OFFSET=*variable*","type":"value"},{"name":"OUTMODEL=","optional":true,"description":"specifies the data table to which to save the gradient boosting model","help":"OUTMODEL=&lt;*libref.*&gt;*data-table*","type":"dataSet"},{"name":"PRINTTARGET","optional":true,"description":"outputs tables that indicate generated columns in the OUT= table from the OUTPUT statement","type":"standalone"},{"name":"RBAIMP","optional":true,"description":"creates a variable importance table by using random branch assignment (RBA)","type":"standalone"},{"name":"RIDGE=","optional":true,"aliases":["L2="],"description":"specifies the L2 norm regularization parameter on prediction","help":"RIDGE=*number*","type":"value"},{"name":"SAMPLINGRATE=","optional":true,"description":"specifies the fraction of the training data to be used for growing each tree in the boosting model","help":"SAMPLINGRATE=*number*","type":"value"},{"name":"SEED=","optional":true,"description":"specifies the initial seed for random number generation for model building","help":"SEED=*number*","type":"value"},{"name":"VARS_TO_TRY=","optional":true,"aliases":["M="],"description":"specifies the number of input variables to consider splitting on in a node, where m ranges from 1 to the number of input variables","help":"VARS_TO_TRY=*m*","type":"value"},{"name":"VII=","optional":true,"aliases":["INTERACTIONIMP="],"description":"calculates the variable interaction importance, which is described in the section {gradboost.details_intimp}","help":"VII=2 | 3","type":"choice"}]},{"name":"AUTOTUNE","description":"searches for the best combination of values of the LASSO=, LEARNINGRATE=, MAXDEPTH=, MINLEAFSIZE=, NTREES=, NUMBIN=, RIDGE=, SAMPLINGRATE=, and VARS_TO_TRY= options in the PROC GRADBOOST statement","help":"AUTOTUNE &lt;options&gt;;                                              ","arguments":[{"name":"TUNINGPARAMETERS=","optional":true,"aliases":["TUNEPARMS="],"description":"specifies which parameters to tune and which ranges to tune over","help":"TUNINGPARAMETERS=(*suboption* | ... | &lt;*suboption*&gt;)","type":"value","arguments":[{"name":"LASSO","description":"specifies information about the L1 regularization to use for tuning the gradient boosting model","help":"LASSO (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum L1 regularization value to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum L1 regularization value to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of L1 regularization values to consider during tuning, where value-list is a space-separated list of numbers greater than or equal to 0","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial L1 regularization value for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes L1 regularization from the tuning process","type":"standalone"}]},{"name":"LEARNINGRATE","description":"specifies information about the learning rate to use for tuning the gradient boosting model","help":"LEARNINGRATE (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum learning rate to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum learning rate to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of learning rates to consider during tuning, where value-list is a space-separated list of numbers greater than 0 and less than or equal to 1","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial learning rate for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the learning rate from the tuning process","type":"standalone"}]},{"name":"MAXDEPTH","description":"specifies information about the maximum depth of trees to use for tuning the gradient boosting model","help":"MAXDEPTH (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum value of the MAXDEPTH= option in the PROC GRADBOOST statement to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum value of the MAXDEPTH= option in the PROC GRADBOOST statement to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of values of the MAXDEPTH= option in the PROC GRADBOOST statement to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial value of the MAXDEPTH= option in the PROC GRADBOOST statement for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"MINLEAFSIZE","description":"specifies information about tuning the leaf size option for training the decision tree","help":"MINLEAFSIZE (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum leaf size value to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum leaf size value to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of leaf size values to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial leaf size for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the leaf size from the tuning process","type":"standalone"}]},{"name":"EXCLUDE","description":"excludes the MAXDEPTH= option from the tuning process","type":"standalone"}]},{"name":"NTREES","description":"specifies information about the number of trees to use for tuning the gradient boosting model","help":"NTREES (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum number of trees to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum number of trees to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of numbers of trees to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial number of trees for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the number of trees from the tuning process","type":"standalone"}]},{"name":"NUMBIN","description":"specifies information about the number of bins to consider during the tuning of the options for PROC GRADBOOST","help":"NUMBIN (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum number of bins to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum number of bins to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of the numbers of bins to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial number of bins for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the number of bins from the tuning process","type":"standalone"}]},{"name":"RIDGE","description":"specifies information about the L2 regularization to use for tuning the gradient boosting model","help":"RIDGE (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum L2 regularization value to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum L2 regularization value to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of L2 regularization values to consider during tuning, where value-list is a space-separated list of numbers greater than or equal to 0","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial L2 regularization value for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes L2 regularization from the tuning process","type":"standalone"}]},{"name":"SAMPLINGRATE","description":"specifies information about the portion of the training data for each boosted tree to use for tuning the gradient boosting model","help":"SAMPLINGRATE (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum sampling rate to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum sampling rate to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of sampling rates to consider during tuning, where value-list is a space-separated list of numbers greater than 0 and less than or equal to 1","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial sampling rate for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the sampling rate from the tuning process","type":"standalone"}]},{"name":"VARS_TO_TRY","description":"specifies information about the number of variables to consider at each split during tree growth","help":"VARS_TO_TRY (LB=*number* UB=*number* VALUES=*value-list* INIT=*number* EXCLUDE)","type":"value","arguments":[{"name":"LB=","description":"specifies the minimum number of variables to consider during tuning","help":"LB=*number*","type":"value"},{"name":"UB=","description":"specifies the maximum number of variables to consider during tuning","help":"UB=*number*","type":"value"},{"name":"VALUES=","description":"specifies a list of numbers of variables to consider during tuning, where value-list is a space-separated list of positive integers","help":"VALUES=*value-list*","type":"value"},{"name":"INIT=","description":"specifies the initial number of variables for the tuner to use","help":"INIT=*number*","type":"value"},{"name":"EXCLUDE","description":"excludes the number of variables from the tuning process","type":"standalone"}]}]}]},{"name":"CODE","description":"writes SAS DATA step code for computing predicted values of the fitted model to a file or to a table","help":"CODE &lt;options&gt;;                                              ","arguments":[{"name":"COMMENT","optional":true,"description":"Adds comments to the generated code","type":"standalone"},{"name":"FILE=","optional":true,"description":"Names the file in which to save the generated code","type":"value"},{"name":"FORMATWIDTH=","optional":true,"description":"Specifies the numeric format width for the regression coefficients","type":"value"},{"name":"INDENTSIZE=","optional":true,"description":"Specifies the number of spaces to indent the generated code","type":"value"},{"name":"LABELID=","optional":true,"description":"Specifies a number used to construct names and labels","type":"value"},{"name":"LINESIZE=","optional":true,"description":"Specifies the line size for the generated code","type":"value"},{"name":"NOTRIM","optional":true,"description":"Compares formatted values, including blank padding","type":"standalone"},{"name":"OUT=","optional":true,"description":"Names an output table in which to save the generated code","type":"value"}]},{"name":"CROSSVALIDATION","description":"performs k-fold cross validation to find the average estimated validation error","help":"CROSSVALIDATION &lt;options&gt;;                                              ","arguments":[{"name":"KFOLD=","optional":true,"description":"specifies the number of partition folds in the cross validation process, where number is between 2 and 20, inclusive","help":"KFOLD=*number*","type":"value"},{"name":"NOPARALLEL","optional":true,"description":"specifies that k-fold cross validation not be run in parallel","type":"standalone"},{"name":"NSUBSESSIONWORKERS=","optional":true,"description":"specifies the number of worker nodes to use in parallel subsessions","help":"NSUBSESSIONWORKERS=*number*","type":"value"}]},{"name":"FREQ","description":"identifies a numeric variable in the input data table that contains the frequency of occurrence of each observation","help":"FREQ  variable;                                              "},{"name":"ID","description":"lists one or more variables that are to be copied from the input data table to the output data tables that are specified in the OUT= option in the OUTPUT statement and the RSTORE= option in the SAVESTATE statement","help":"ID *variables*;                                              "},{"name":"INPUT","description":"names input variables that share common options","help":"INPUT  variables &lt;/ options&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the level of measurement of the variables","help":"LEVEL={INTERVAL | NOMINAL}","type":"choice"},{"name":"MONOTONIC=","optional":true,"followsDelimiter":"/","description":"requests that the gradient boosting model be built by requiring monotonic constraints on the model with respect to the variables","help":"MONOTONIC={DECREASING | INCREASING}","type":"choice"}]},{"name":"OUTPUT","description":"creates an output data table that contains the results of running PROC GRADBOOST","help":"OUTPUT  OUT=*libref.data-table*&lt;option&gt;;                                              ","arguments":[{"name":"OUT=","optional":true,"description":"names the output data table for PROC GRADBOOST to use","help":"OUT=*libref.data-table*","type":"dataSet"},{"name":"COPYVAR=","optional":true,"aliases":["COPYVARS="],"description":"lists one or more variables from the input data table to be transferred to the output data table","help":"COPYVAR={*variable*}","type":"value"},{"name":"ROLE","optional":true,"description":"generates a numeric variable that indicates the role played by each observation in fitting the model","help":"ROLE&lt;={*name*}&gt;","type":"standaloneOrValue"}]},{"name":"PARTITION","description":"specifies how observations in the input data set are logically partitioned into disjoint subsets for model training, validation, and testing","help":"PARTITION  partition-option;                                              ","arguments":[{"name":"FRACTION","optional":true,"description":"randomly assigns specified proportions of the observations in the input data table to the roles","help":"FRACTION(&lt;TEST=*fraction*&gt; &lt;VALIDATE=*fraction*&gt; &lt;SEED=*number*&gt;)","type":"standaloneOrValue"},{"name":"ROLE=","optional":true,"aliases":["ROLEVAR="],"description":"names the variable in the input data table whose values are used to assign roles to each observation","help":"ROLE={*variable* (&lt;TEST=*'value'*&gt; &lt;TRAIN=*'value'*&gt; &lt;VALIDATE=*'value'*&gt;) }","type":"value"}]},{"name":"SAVESTATE","description":"creates an analytic store for the model and saves it as a binary object in a data table","help":"SAVESTATE  RSTORE=*libref.data-table*;                                              ","arguments":[{"name":"RSTORE=","optional":true,"description":"specifies a data table in which to save the analytic store for the model","help":"RSTORE=*libref.data-table*","type":"dataSet"}]},{"name":"TARGET","description":"names the variable whose values PROC GRADBOOST predicts","help":"TARGET  variable &lt;/ LEVEL={NOMINAL | INTERVAL}&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the level of measurement","help":"LEVEL={NOMINAL | INTERVAL}","type":"choice"}]},{"name":"MITIGATEBIAS","description":"enables PROC GRADBOOST to iteratively train a model while minimizing the bias metric that you specify","help":"MITIGATEBIAS  SENSITIVEVAR=*variable* PREDICTEDVARS=(*variable-names*) PREDICTEDEVENTS=\"*event-list*\" &lt;options&gt;;                                              ","arguments":[{"name":"PREDICTEDEVENTS=","optional":true,"aliases":["PEVENTS="],"description":"specifies the events that correspond to each variable in the PREDICTEDVARS= option","help":"PREDICTEDEVENTS=\"*event-list*\"","type":"value"},{"name":"PREDICTEDVARS=","optional":true,"aliases":["PVARS="],"description":"specifies the names of the variables that contain the posterior probability for each level in model prediction that corresponds to the response (target) variable","help":"PREDICTEDVARS=(*variable-names*)","type":"value"},{"name":"SENSITIVEVAR=","optional":true,"description":"specifies the sensitive variable to use in order to reduce the value of the bias measurement that you specify in the BIASMETRIC= option","help":"SENSITIVEVAR=*variable*","type":"value"},{"name":"BIASMETRIC=","optional":true,"description":"specifies the type of bias measurement","help":"BIASMETRIC=*bias-metric*","type":"value"},{"name":"BOUND=","optional":true,"description":"specifies the bound value for the exponentiated gradient reduction algorithm","help":"BOUND=*number*","type":"value"},{"name":"DELIMITER=","optional":true,"aliases":["DLM="],"description":"specifies the delimiter to be used to separate events that you specify in the PREDICTEDEVENTS= option","help":"DELIMITER=\"*character*\"","type":"value"},{"name":"LEARNINGRATE=","optional":true,"description":"specifies the step size to use in updating the exponentiated gradient reduction algorithm","help":"LEARNINGRATE=*number*","type":"value"},{"name":"LOGLEVEL=","optional":true,"description":"specifies the level of log information to print","help":"LOGLEVEL=0 | 1 | 2","type":"choice"},{"name":"MAXITER=","optional":true,"description":"specifies the maximum number of iterations to run the exponentiated gradient reduction algorithm","help":"MAXITER=*number*","type":"value"},{"name":"SEED=","optional":true,"description":"specifies the seed for the pseudorandom number generator","help":"SEED=*number*","type":"value"},{"name":"TARGETEVENT=","optional":true,"description":"specifies the formatted value of the response (target) variable that represents the event of interest","help":"TARGETEVENT=\"*event*\"","type":"value"},{"name":"TOLERANCE=","optional":true,"description":"specifies the parity constraint violation tolerance","help":"TOLERANCE=*number*","type":"value"},{"name":"TUNEBOUND","optional":true,"description":"specifies that the bound value must be tuned","type":"standalone"}]},{"name":"TRANSFERLEARN","description":"enables you to train the gradient boosting model by using auxiliary data that are added to your training data","help":"TRANSFERLEARN  variable &lt;/ options&gt;;                                              ","arguments":[{"name":"BURN=","optional":true,"followsDelimiter":"/","description":"specifies the number of trees to create before down-weighting any observation in the auxiliary data","help":"BURN=*number*","type":"value"},{"name":"SHRINKAGE=","optional":true,"followsDelimiter":"/","description":"specifies the number to apply as the weighting factor for down-weighting auxiliary data, where number must be between 0 and 1, exclusive","help":"SHRINKAGE=*number*","type":"value"},{"name":"TRIMMING=","optional":true,"followsDelimiter":"/","description":"specifies the number to use as a fraction of the distribution of gradients on the training data beyond which auxiliary observations are down-weighted, where number must be greater than 0 and less than or equal to 1/2","help":"TRIMMING=*number*","type":"value"}]},{"name":"VIICODE","description":"writes SAS DATA step code to a file or to a catalog entry","help":"VIICODE &lt;options&gt;;                                              ","arguments":[{"name":"ADD","optional":true,"description":"requests that the newly created variables be of the form V + W","type":"standalone"},{"name":"LIMIT=","optional":true,"description":"specifies the maximum number of new variables to create","help":"LIMIT=*number*","type":"value"},{"name":"MISS","optional":true,"description":"requests that the generated code handle missing values","type":"standalone"},{"name":"MULTIPLY","optional":true,"description":"requests that the newly created variables be of the form V W","type":"standalone"},{"name":"SUBTRACT","optional":true,"description":"requests that the newly created variables be of the form V - W","type":"standalone"},{"name":"THRESHOLD=","optional":true,"description":"requests that interactions with an importance less than number times the maximum interaction importance be ignored, where number must be between 0 and 1","help":"THRESHOLD=*number*","type":"value"}]},{"name":"WEIGHT","description":"variable is used to weight each observation to perform a weighted analysis of the data","help":"WEIGHT  variable;                                              "}],"supportSiteInformation":{"docsetId":"casml","docsetVersion":"latest","docsetTargetFile":"casml_gradboost_toc.htm"}}