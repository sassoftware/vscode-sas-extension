{"name":"HADOOP","statements":[{"name":"PROC HADOOP","description":"Controls access to the Hadoop server.","help":"PROC HADOOP \n                <hadoop-server-options>;\n\tHDFS \n                    <hadoop-server-options>\n                    <hdfs-command-options>;\n                \n\tMAPREDUCE \n                    <hadoop-server-options>\n                    <mapreduce-options>;\n                \n\tPIG \n                    <hadoop-server-options>\n                    <pig-code-options>;\n                \n\tPROPERTIES \n                    <configuration-properties>;\n            ","arguments":[{"name":"CFG=","optional":true,"aliases":["OPTIONS="],"description":"identifies the Hadoop configuration file to use in order to connect to the Hadoop server.","help":"CFG=*fileref* | '*external-file*'","type":"choice","arguments":[{"name":"fileref","placeholder":true,"description":"specifies the SAS fileref that is assigned to the Hadoop configuration file. To assign a fileref, use the FILENAME statement.","type":"value"},{"name":"'external-file'","placeholder":true,"description":"is the physical location of the XML document. Include the complete pathname and the filename. The maximum length is 200 characters.","type":"value"}]},{"name":"MAXWAIT=","optional":true,"description":"specifies the HTTP status response time when using WebHDFS.","help":"MAXWAIT=*wait-interval*","type":"value"},{"name":"PASSWORD=","optional":true,"aliases":["PASS="],"description":"is the password for the user ID on the Hadoop server.","help":"PASSWORD='*password*'","type":"value"},{"name":"USERNAME=","optional":true,"aliases":["USER="],"description":"is an authorized user ID on the Hadoop server.","help":"USERNAME='*ID*'","type":"value"},{"name":"VERBOSE","optional":true,"description":"enables additional messages that are displayed on the SAS log.","type":"standalone"}]},{"name":"HDFS","description":"Submits Hadoop Distributed File System (HDFS) commands.","help":"HDFS \n                        <hadoop-server-options>\n                        <hdfs-command-options>;","arguments":[{"name":"CAT=","optional":true,"description":"displays the contents of the specified file or files.","help":"CAT='HDFS-file' <ONLY=n>\n                                <RECURSE>\n                                <SHOW_FILENAME>","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies a pathname or a pathname and a filename. You can use wildcard characters to substitute for any other character or characters in the pathname or the filename. Use * to match one or more characters, or ? to match a single character.","type":"value"},{"name":"ONLY=","description":"displays only the specified number of lines from the beginning of the file. For example, only=10 displays the first ten lines of a file. This option is helpful to determine the contents of a file.","help":"ONLY=*n*","type":"value"},{"name":"RECURSE","description":"specifies to display the contents for all files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified HDFS file is not a directory.","type":"standalone"},{"name":"SHOW_FILENAME","description":"includes the name of the file in the output. For example, hdfs cat='/tmp/*.txt' show_filename only=10 recurse; displays in the SAS log the name of the file and the first ten lines of all .txt files that are found in the /tmp directory and all of its subdirectories.","type":"standalone"}]},{"name":"CHMOD=","optional":true,"description":"changes file access permissions for one or more HDFS files.","help":"CHMOD='HDFS-file' PERMISSION=<'>value<'>\n                                <RECURSE>","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies a pathname or a pathname and a filename. You can use a wildcard character to substitute for any character or characters in the pathname or filename. Use * to match any number of characters, or ? to match a single character.","type":"value"},{"name":"PERMISSION=","description":"specifies a value that represents three levels of permissions, which are owner, group, and user. All three permission levels are required. You can specify the permissions in read, write, and execute (rwx) symbolic notation or octal notation.\n• For                                                   the rwx symbolic notation, use nine characters.                                                   The first set of three characters represents what                                                   the owner can do, the second set represents what a                                                   group can do, and the third set represents what a                                                   user can do. For each set of three characters, the                                                   first position must be r or - (for read), the                                                   second position must be w or - (for write), and                                                   the third position must be x or - (for execute).                                                   For example,                                                                                                      specifies that the owner has Read, Write, and                                                   Execute permission, group members have Read and                                                   Execute permission, and users have Read and                                                   Execute permission. \n• For                                                   octal notation, use three digits. Each digit                                                   represents the permissions for owner, group, and                                                   user. Each digit must be from 0 to 7. The octal                                                   notation represents the same numeric value as the                                                   rwx symbolic notation. That is, 4 is r, 2 is w, 1                                                   is x, and 0 is -. For example,                                                    specifies                                                   that the owner has Read, Write, and Execute                                                   permission, group members have Read and Execute                                                   permission, and users have Read and Execute                                                   permission.","help":"PERMISSION=*value*","type":"value"},{"name":"RECURSE","description":"specifies to change the access permissions to all files and directories in the specified pathname and all files and directories that are in subdirectories. RECURSE has no effect if the specified HDFS file is not a directory. For example, hdfs chmod='/tmp' permission=755 recurse; changes the permissions to the specified directory and all files and subdirectories within the directory.","type":"standalone"}]},{"name":"COPYFROMLOCAL=","optional":true,"description":"copies the specified local file to an HDFS output location.","help":"COPYFROMLOCAL='local-file' <DELETESOURCE>\n                                <OVERWRITE>\n                                <RECURSE>\n                            ","type":"value","arguments":[{"name":"'local-file'","placeholder":true,"description":"specifies the complete pathname and the filename. You can use a wildcard character to substitute for any other character or characters in the pathname or the filename. Use * to match any number of characters, or ? to match a single character.","type":"value"},{"name":"DELETESOURCE","description":"deletes the input source file after a copy command.","type":"standalone"},{"name":"OVERWRITE","description":"specifies to overwrite an existing output location.","type":"standalone"},{"name":"RECURSE","description":"specifies to copy all the files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified file is not a directory.","type":"standalone"}]},{"name":"COPYTOLOCAL=","optional":true,"description":"copies the specified HDFS file to a local output location.","help":"COPYTOLOCAL='HDFS-file<DELETESOURCE>\n                                <KEEPCRC>\n                                <OVERWRITE>\n                                <RECURSE>\n                            ","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies the complete pathname and the filename. You can use a wildcard character to substitute for any other character or characters in the pathname or the filename. Use * to match any number of characters, or ? to match a single character.","type":"value"},{"name":"DELETESOURCE","description":"deletes the input source file after a copy command.","type":"standalone"},{"name":"KEEPCRC","description":"saves the Cyclic Redundancy Check (CRC) file after the copy command to a local output location. The CRC file is saved to the same location that is specified in the OUT= option. The CRC file is used to ensure the correctness of the file being copied. By default, the CRC file is deleted.","type":"standalone"},{"name":"OVERWRITE","description":"specifies to overwrite an existing output location.","type":"standalone"},{"name":"RECURSE","description":"specifies to copy all the files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified HDFS file is not a directory.","type":"standalone"}]},{"name":"DELETE=","optional":true,"description":"deletes the specified HDFS file.","help":"DELETE='HDFS-file' <NOWARN>\n                            ","type":"value","arguments":[{"name":"HDFS-file","placeholder":true,"description":"specifies a pathname or a pathname and a filename. If you include the filename, then only that file is deleted. If you do not include a filename, then all the files in the specified pathname and all the files that are in subdirectories are deleted. You can use a wildcard character to substitute for any other character or characters in the pathname or the filename. Use * to match any number of characters, or ? to match a single character.","type":"value"},{"name":"NOWARN","description":"suppresses the warning message when there is an attempt to delete a file that does not exist.","type":"standalone"}]},{"name":"LS=","optional":true,"description":"lists the files in the specified HDFS pathname.","help":"LS='*HDFS-pathname*' &lt;RECURSE&gt;","type":"value","arguments":[{"name":"HDFS-pathname","placeholder":true,"description":"specifies a pathname. You can use a wildcard character to substitute for any character or characters in the pathname. Use * to match any number of characters, or ? to match a single character.","type":"value"},{"name":"RECURSE","description":"specifies to list the files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified file is not a directory.","type":"standalone"}]},{"name":"MKDIR=","optional":true,"description":"creates the specified HDFS pathname. Specify the complete HDFS pathname.","help":"MKDIR='*HDFS-pathname*'","type":"value"},{"name":"OUT=","optional":true,"description":"specifies the output location for the contents, which can be an external file for your machine or a fileref that is assigned with the FILENAME statement.","help":"OUT='*output-location*'","type":"value"},{"name":"RENAME=","optional":true,"description":"renames the specified HDFS file.","help":"RENAME='*HDFS-file*","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies the pathname and the filename to rename.","type":"value"}]}]},{"name":"MAPREDUCE","description":"Submits MapReduce programs into a Hadoop cluster.","help":"\n                        \n\tMAPREDUCE <hadoop-server-options>\n                            <mapreduce-options>;\n                    ","arguments":[{"name":"COMBINE=","optional":true,"description":"specifies the name of the combiner class in dot notation.","help":"COMBINE='*class-name*'","type":"value"},{"name":"DELETERESULTS","optional":true,"description":"specifies to delete the output directory, if it exists, before starting the MapReduce job.","type":"standalone"},{"name":"GROUPCOMPARE=","optional":true,"description":"specifies the name of the grouping comparator (GroupComparator) class in dot notation.","help":"GROUPCOMPARE='*class-name*'","type":"value"},{"name":"INPUT=","optional":true,"description":"specifies the HDFS pathname to the MapReduce input file.","help":"INPUT='*HDFS-pathname*'","type":"value"},{"name":"INPUTFORMAT=","optional":true,"description":"specifies the name of the input format class in dot notation.","help":"INPUTFORMAT='*class-name*'","type":"value"},{"name":"JAR=","optional":true,"description":"specifies the locations of the JAR files that contain the MapReduce program and named classes.","help":"JAR='*external-file(s)*'","type":"value"},{"name":"MAP=","optional":true,"description":"specifies the name of the map class in dot notation.","help":"MAP='*class-name*'","type":"value"},{"name":"OUTPUT=","optional":true,"description":"when connecting to the Hadoop server, specifies a new HDFS pathname for the MapReduce output.","help":"OUTPUT='*HDFS-pathname*'","type":"value"},{"name":"OUTPUTFORMAT=","optional":true,"description":"specifies the name of the output format class in dot notation.","help":"OUTPUTFORMAT='*class-name*'","type":"value"},{"name":"OUTPUTKEY=","optional":true,"description":"specifies the name of the output key class in dot notation.","help":"OUTPUTKEY='*class-name*'","type":"value"},{"name":"OUTPUTVALUE=","optional":true,"description":"is the name of the output value class in dot notation.","help":"OUTPUTVALUE='*class-name*'","type":"value"},{"name":"PARTITIONER=","optional":true,"description":"specifies the name of the partitioner class in dot notation.","help":"PARTITIONER='*class-name*'","type":"value"},{"name":"REDUCE=","optional":true,"description":"specifies the name of the reducer class in dot notation.","help":"REDUCE='*class-name*'","type":"value"},{"name":"REDUCETASKS=","optional":true,"description":"specifies the number of reduce tasks.","help":"REDUCETASKS=*integer*","type":"value"},{"name":"REPLACE","optional":true,"description":"when connecting to Hadoop through the Oozie RESTful API, specifies to delete any existing workflow and JAR file(s) in the Oozie application before copying new files to the working directory.","type":"standalone"},{"name":"SORTCOMPARE=","optional":true,"description":"specifies the name of the sort comparator class in dot notation.","help":"SORTCOMPARE='*class-name*'","type":"value"},{"name":"WORKINGDIR=","optional":true,"description":"specifies the name of the HDFS working directory pathname.","help":"WORKINGDIR='*HDFS-pathname*'","type":"value"}]},{"name":"PIG","description":"Submits Pig language code into a Hadoop cluster.","help":"\n                        \n\tPIG \n                            <hadoop-server-options>\n                            <pig-code-options>;\n                    ","arguments":[{"name":"CODE=","optional":true,"description":"specifies the source that contains the Pig language code to execute.","help":"CODE=*fileref* | '*external-file*'","type":"choice","arguments":[{"name":"fileref","placeholder":true,"description":"is a SAS fileref that is assigned to the source file. To assign a fileref, use the FILENAME statement.","type":"value"},{"name":"'external-file'","placeholder":true,"description":"is the physical location of the source file. Specify the complete pathname and the filename.","type":"value"}]},{"name":"DELETERESULTS","optional":true,"description":"when connecting to the Hadoop server through the Oozie RESTful API, specifies to delete the existing output location before starting the Oozie job.","type":"standalone"},{"name":"OUTPUT=","optional":true,"description":"when connecting to the Hadoop server through the Oozie RESTful API, specifies the existing output location to delete before starting the Oozie job.","help":"OUTPUT='*HDFS-pathname*'","type":"value"},{"name":"PARAMETERS=","optional":true,"description":"specifies the source that contains parameters to be passed as arguments when the Pig code executes.","help":"PARAMETERS=*fileref* | '*external-file*'","type":"choice","arguments":[{"name":"fileref","placeholder":true,"description":"is a SAS fileref that is assigned to the source file. To assign a fileref, use the FILENAME statement.","type":"value"},{"name":"'external-file'","placeholder":true,"description":"is the physical location of the source file. Specify the complete pathname and the filename.","type":"value"}]},{"name":"REGISTERJAR=","optional":true,"description":"specifies the locations of the JAR files that contain the Pig scripts to execute.","help":"REGISTERJAR='*external-file(s)*'","type":"value"},{"name":"REPLACE","optional":true,"description":"when connecting to Hadoop through the Oozie RESTful API, specifies to delete any existing workflow and JAR file(s) in the Oozie application before copying new files to the working directory.","type":"standalone"},{"name":"WORKINGDIR=","optional":true,"description":"when connecting to Hadoop through the Oozie RESTful API, specifies the HDFS pathname for the Oozie workflow application directory.","help":"WORKINGDIR='*HDFS-pathname*'","type":"value"}]},{"name":"PROPERTIES","aliases":["PROP"],"description":"Submits configuration properties to the Hadoop server.","help":"PROPERTIES  'configuration-property-1' <'configuration-property-2'>\n                         ...;","arguments":[{"name":"configuration-property","placeholder":true,"description":"specifies any property that can be specified in a Hadoop configuration file.","type":"value"}]}],"supportSiteInformation":{"docsetId":"proc","docsetVersion":"v_002","docsetTargetFile":"p0esxx8qmpi2p8n1mdmwn1al94a7.htm"}}