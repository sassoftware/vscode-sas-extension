{"name":"HPNEURAL","statements":[{"name":"PROC HPNEURAL","description":"The HPNEURAL procedure is a high-performance procedure that trains a multilayer perceptron neural network. For more information about multilayer perceptron neural networks, see Bishop (1995). PROC HPNEURAL can also use the trained network to score the input data set. † PROC HPNEURAL reads and writes data in distributed form and makes full use of multicore computers and distributed computing environments to perform training and scoring. † Training a multilayer perceptron neural network requires the unconstrained minimization of a nonlinear objective function. Because there are currently no practical methods to guarantee finding a global minimum of that objective function, one way to be reasonably sure of finding a good solution is to train the network multiple times using different sets of initial values for the weights. Thus, even problems with smaller numbers of variables and training observations can benefit from the use of multicore computers and distributed computing environments.","help":"PROC HPNEURAL <DATA=SAS-data-set> <DISTR=ALL | SPLIT> <NOPRINT>;     \n\tARCHITECTURE <LAYER1> <LAYER1SKIP> <LOGISTIC> ...; \n   \n\tCODE <FILE=’external-file’ | fileref > ;     \n\tHIDDEN number ;     \n\tID variables ;     \n\tINPUT <LEVEL=<INT | NOM>> <MISSING=<MAP>> ; \n   \n\tPARTITION <FRACTION( TRAIN=number | VALIDATE=number )> <ROLEVAR=variable( TRAIN=value | VALIDATE=value )> ;     \n\tPERFORMANCE <COMMIT=n> <CPUCOUNT=<ACTUAL | <num>>> <DATASERVER=“name”> ...; \n   \n\tSCORE <MODEL=SAS-data-set> <OUT=SAS-data-set > ; \n   \n\tTARGET <LEVEL=<INT | NOM>> ; \n   \n\tTRAIN <MAXITER=number> <NUMTRIES=number> <VALID=_NONE_> ...; \n   \n\tWEIGHT <_INVERSE_PRIORS_> ; ","arguments":[{"name":"DATA=","optional":true,"description":"Names the SAS data set that contains the training and validation observations to be used by PROC HPNEURAL to train the neural network or that contains the observations to be scored when you are performing stand-alone scoring. The default input data set is the most recently created data set.","help":"DATA=*SAS-data-set*","type":"dataSet"},{"name":"DISTR=","optional":true,"description":"Specifies whether the input data set is to be replicated in the memory of each node in a distributed computing environment. If this option is not specified, PROC HPNEURAL makes this decision automatically based on the size of the input data set. This option is ignored if PROC HPNEURAL is not running in a distributed computing environment. When PROC HPNEURAL runs in a distributed computing environment, PROC HPNEURAL usually divides the input data set among all the nodes to minimize the time it takes to optimize each try. However, if the input data set is small, dividing the data in this way might be inefficient because of the interconnect delay (the time it takes to send partial results between nodes). It might be more efficient to have each node have a complete copy of the data and run each try in parallel on separate nodes. Each try might take longer because it uses only a single node, but it could take less time to finish all the tries because the tries are running in parallel.","help":"DISTR=ALL | SPLIT","type":"choice","arguments":[{"name":"ALL","description":"Forces the data to be redistributed so that each node has a complete in-memory copy.","type":"standalone"},{"name":"SPLIT","description":"Prevents the data from being redistributed.","type":"standalone"}]},{"name":"NOPRINT","optional":true,"description":"Syntax: NOPRINT specifies that no ODS tables be created.","type":"standalone"}]},{"name":"ARCHITECTURE","description":"The ARCHITECTURE statement specifies the architecture of the neural network to be trained.","help":"ARCHITECTURE &lt;LAYER1&gt; &lt;LAYER1SKIP&gt; &lt;LOGISTIC&gt; ...","arguments":[{"name":"LAYER1","optional":true,"description":"Specifies a multilayer perceptron with a single hidden layer.","type":"standalone"},{"name":"LAYER1SKIP","optional":true,"description":"Specifies a multilayer perceptron with a single hidden layer and additional connections between each input and each target neuron. Logistic regression is used to initialize the network for the first try.","type":"standalone"},{"name":"LAYER2","optional":true,"description":"Specifies a multilayer perceptron with two hidden layers. The number of hidden neurons is split equally between the first and second layer. If the number of hidden neurons is odd, the first hidden layer has the extra neuron.","type":"standalone"},{"name":"LAYER2SKIP","optional":true,"description":"Specifies a multilayer perceptron with two hidden layers and additional connections between each input and each target neuron. The number of hidden neurons is split equally between the first and second layer. If the number of hidden neurons is odd, the first hidden layer has the extra neuron. Logistic regression is used to initialize the network for the first try.","type":"standalone"},{"name":"LOGISTIC","optional":true,"description":"Specifies a multilayer perceptron with no hidden units (which is equivalent to a logistic regression). If you specify this architecture, the HIDDEN statement is not allowed.","type":"standalone"}]},{"name":"CODE","description":"The CODE statement uses the current neural network model to generate SAS DATA step statements and save them in an external text file that can later be used to score a data set. The file does not contain the surrounding PROC and RUN statements. The DATA step statements can be used with the standard DATA step, PROC DS2, or PROC HPDS2. The CODE statement is optional.","help":"CODE &lt;FILE=’external-file’ | fileref &gt; ","arguments":[{"name":"FILE=","optional":true,"description":"FILE=’external-file’ specifies an external text file where the generated statements are saved.","type":"value"}]},{"name":"HIDDEN","description":"The HIDDEN statement specifies the number of hidden neurons in the network. The number must be an integer greater than or equal to 1 (2 for two-layer architectures). For two-layer architectures (LAYER2 and LAYER2SKIP in the ARCHITECTURE statement), the hidden neurons are split between the first and second layer. In this case, if the number of hidden neurons is odd, the first hidden layer has the extra neuron. All hidden neurons use a hyperbolic-tangent activation function. When training, you must include exactly one HIDDEN statement, unless you specify ARCHITECTURE LOGISTIC (in which case the HIDDEN statement is not allowed). The HIDDEN statement is not allowed when you do stand-alone scoring.","help":"HIDDEN number "},{"name":"ID","description":"The ID statement lists one or more variables from the input data set that are transferred to the output data set that is specified in the SCORE statement. The ID statement is optional.","help":"ID variables "},{"name":"INPUT","description":"The INPUT statement identifies the variables in the input data set that are inputs to the neural network. When training, you must include one or more INPUT statements. You need more than one INPUT statement when you have both interval and nominal input variables. The INPUT statement is not allowed when you do stand-alone scoring. All interval input variables are automatically standardized to the range [–1, 1]. If an observation has missing values for any of the specified input variables, the observation is not used for training or for computing validation error.","help":"INPUT &lt;LEVEL=&lt;INT | NOM&gt;&gt; &lt;MISSING=&lt;MAP&gt;&gt; ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"Specifies whether the variables are interval variables (INT), which must be numeric, or nominal variables (NOM), also known as classification variables, which can be numeric or character. The default for the LEVEL option is INT.","help":"LEVEL=INT | NOM","type":"choice","arguments":[{"name":"INT","followsDelimiter":"/","description":"Specifies that the variables are interval variables (INT), which must be numeric.","type":"standalone"},{"name":"NOM","followsDelimiter":"/","description":"Specifies that the variables are nominal variables (NOM), also known as classification variables, which can be numeric or character.","type":"standalone"}]},{"name":"MISSING=","optional":true,"followsDelimiter":"/","description":"Specifies that the missing value for nominal variables should be treated as a valid level (mapped to level 0). This option is not allowed for interval variables.","help":"MISSING=MAP*MAP*","type":"value","arguments":[{"name":"MAP","followsDelimiter":"/","description":"Specifies that the missing value for nominal variables should be treated as a valid level (mapped to level 0).","type":"standalone"}]}]},{"name":"PARTITION","description":"The PARTITION statement specifies how to divide the input data set into a training subset and a validation subset. The statement implements two alternate methods of specifying the split between the training and validation data. Either you can explicitly specify training observations and validation observations by specifying ROLEVAR=variable, where variable is a variable in the input data set, or you can specify that an approximate fraction of the input data set be used for training observations or validation observations by specifying FRACTION( TRAIN=number ) or FRACTION( VALIDATE=number ).","help":"PARTITION &lt;FRACTION( TRAIN=number | VALIDATE=number )&gt; &lt;ROLEVAR=variable( TRAIN=value | VALIDATE=value )&gt; ","arguments":[{"name":"FRACTION=","optional":true,"description":"Specifies the approximate fraction (between 0 and 1) of the input data set to be used for training or validation. If you specify TRAIN=number, then approximately the fraction of the data set specified by number is used as training observations, and the rest are used for validation observations. If you specify VALIDATE=number, then approximately the fraction of the data set specified by number is used as validation observations. The split between training and validation observations can only approximate the requested fraction because that fraction is used as a cutoff value for a pseudorandom number generator to determine the actual split. If you require a more accurate split or a split that is guaranteed to be identical across different distributed computing environments, you must use the ROLEVAR option to specify the split explicitly.","help":"FRACTION=TRAIN= | VALIDATE=","type":"choice","arguments":[{"name":"TRAIN=","type":"value"},{"name":"VALIDATE=","type":"value"}]},{"name":"ROLEVAR=","optional":true,"description":"Specifies that the variable in the input data set be used to decide whether an observation is used for training or for validation. You can specify either the value used to identify training observations or the value used to identify validation observations. If you specify TRAIN=value, then an observation is used for training if the value of variable equals value; otherwise the observation is used for validation. If you specify VALIDATE=value, then an observation is used for validation if the value of variable equals value; otherwise the observation is used for training.","help":"ROLEVAR=TRAIN= | VALIDATE=","type":"choice","arguments":[{"name":"TRAIN=","type":"value"},{"name":"VALIDATE=","type":"value"}]}]},{"name":"PERFORMANCE","description":"The PERFORMANCE statement defines performance parameters for multithreaded and distributed computing.","help":"PERFORMANCE &lt;COMMIT=n&gt; &lt;CPUCOUNT=&lt;ACTUAL | &lt;num&gt;&gt;&gt; &lt;DATASERVER=“name”&gt; ...","arguments":[{"name":"COMMIT=","optional":true,"description":"Requests that the High-Performance Analytics procedure write periodic updates to the SAS Log when observations are sent from the client to the appliance for distributed processing.","help":"COMMIT=*n*","type":"value"},{"name":"CPUCOUNT=","optional":true,"description":"Specifies how many processors the procedure assumes are available on each host in the computing environment. num can be any integer from 1 to 256. CPUCOUNT=ACTUAL sets CPUCOUNT to the number of physical processors available. This number can be less than the physical number of CPUs if the SAS process has been restricted by system administration tools. Setting CPUCOUNT= to a number greater than the actual number of available CPUs might result in reduced performance. This option overrides the CPUCOUNT= SAS system option.","help":"CPUCOUNT=ACTUAL | &lt;*num*&gt;","type":"choice","arguments":[{"name":"ACTUAL","description":"Sets CPUCOUNT to the number of physical processors available. This number can be less than the physical number of CPUs if the SAS process has been restricted by system administration tools.","type":"standalone"},{"name":"num","placeholder":true,"description":"Replace <num> with an actual number. Setting CPUCOUNT= to a number greater than the actual number of available CPUs might result in reduced performance. This option overrides the CPUCOUNT= SAS system option.","type":"standaloneOrValue"}]},{"name":"DATASERVER=","optional":true,"description":"Specifies the name of the server on Teradata systems as defined through the hosts file and as used in the LIBNAME statement for Teradata. For example, if the hosts file defines myservercop1 33.44.55.66 as the server for Teradata, then a LIBNAME specification would be as follows: libname TDLib teradata server=myserver user= password= database= ; A PERFORMANCE statement to induce running alongside the Teradata server would specify the following:","type":"value"},{"name":"DETAILS","optional":true,"description":"Requests a table that shows a timing breakdown of the procedure steps.","type":"standalone"},{"name":"HOST=","optional":true,"aliases":["GRIDHOST="],"description":"Specifies the name of the appliance host in single or double quotes. If the HOST= option is specified, it overrides the value of the GRIDHOST environment variable.","type":"value"},{"name":"INSTALL=","optional":true,"aliases":["INSTALLLOC="],"description":"Specifies the directory in which the High-Performance Analytics shared libraries are installed on the appliance. Specifying the INSTALL= option overrides the GRIDINSTALLLOC environment variable.","type":"value"},{"name":"NODES=","optional":true,"aliases":["NNODES="],"description":"Specifies the number of nodes in the distributed computing environment, provided that the data are not processed alongside the database.","type":"value"},{"name":"NTHREADS=","optional":true,"description":"Specifies the number of threads for analytic computations and overrides the SAS system option THREADS | NOTHREADS. If you do not specify the NTHREADS= option, the number of threads are determined based on the number of CPUs on the host on which the analytic computations execute. The algorithm by which a CPU count is converted to a thread count is specific to the High- Performance Analytics procedure. Most procedures create one thread per CPU for the analytic computations. By default, High-Performance Analytics procedures execute in multiple concurrent threads unless turned off by the NOTHREADS system option or you force single-threaded execution with NTHREADS=1. The largest number that can be specified for n is 256. Individual High-Performance Analytics procedures can impose more stringent limits if called for by algorithmic considerations. You can affect the determination of the CPU count with the CPUCOUNT= option in the PERFORMANCE statement.","help":"NTHREADS=*n*","type":"value"},{"name":"TIMEOUT=","optional":true,"description":"Specifies the timeout in seconds for a High-Performance Analytics procedure to wait for a connection to the appliance and establish a connection back to the client. The default is s=120 seconds. If jobs are submitted to the appliance through workload management tools that might suspend access to the appliance for a longer period, you might want to increase the timeout value.","help":"TIMEOUT=*s*","type":"value"}]},{"name":"SCORE","description":"The SCORE statement causes the HPNEURAL procedure to write the network’s target and predicted output for each observation in the input data set to the output data set that is specified by the OUT option, along with any variables from the input data set that are specified in the ID statement. When you are training, the SCORE statement is optional but the MODEL= keyword is not allowed. When you are doing stand-alone scoring, the SCORE statement is required and the MODEL= keyword must be used.","help":"SCORE &lt;MODEL=SAS-data-set&gt; &lt;OUT=SAS-data-set &gt; ","arguments":[{"name":"MODEL=","optional":true,"description":"Specifies the data set that contains the model parameters for a previously trained network. You can specify this keyword only when you are doing stand-alone scoring.","help":"MODEL=*SAS-data-set*","type":"dataSet"},{"name":"OUT=","optional":true,"description":"Specifies the data set to contain the predicted values of the target variables. For nominal variables, each observation also contains the computed probabilities of each class level. This keyword is required.","type":"value"}]},{"name":"TARGET","description":"The TARGET statement identifies the variables in the input data set that the network is to be trained to predict. The default for the LEVEL= option is INT. When training, you must include one or more TARGET statements. You need more than one TARGET statement when you have both interval and nominal target variables. The TARGET statement is not allowed when you do stand-alone scoring. All interval target variables are automatically standardized to the range [0.1, 0.9]. The HPNEURAL procedure automatically converts them back to their original scale before it computes fit statistics and writes predictions to the scoring data set. For interval variables, all target neurons use a sigmoid activation function.","help":"TARGET &lt;LEVEL=&lt;INT | NOM&gt;&gt; ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"Specifies whether the variables are interval variables (INT), which must be numeric, or nominal variables (NOM), also known as classification variables, which can be numeric or character. The default for the LEVEL option is INT.","help":"LEVEL=INT | NOM","type":"choice","arguments":[{"name":"INT","followsDelimiter":"/","description":"Specifies that the variables are interval variables (INT), which must be numeric.","type":"standalone"},{"name":"NOM","followsDelimiter":"/","description":"Specifies that the variables are nominal variables (NOM), also known as classification variables, which can be numeric or character.","type":"standalone"}]}]},{"name":"TRAIN","description":"The TRAIN statement causes the HPNEURAL procedure to use the training data that are specified in the PROC HPNEURAL statement to train a neural network model whose structure is specified in the ARCHITECTURE, INPUT, TARGET, and HIDDEN statements. The goal of training is to determine a set of network weights that best predicts the targets in the training data while still doing a good job of predicting targets of unseen data (that is, generalizing well and not overfitting).","help":"TRAIN &lt;MAXITER=number&gt; &lt;NUMTRIES=number&gt; &lt;VALID=_NONE_&gt; ...","arguments":[{"name":"MAXITER=","optional":true,"description":"Syntax: MAXITER=number specifies the maximum number of iterations (weight adjustments) for the optimizer to make before terminating. Setting number to a large value does not mean that the optimizer actually iterates that many times. Often, training or validation error stops improving much sooner, usually after a few hundred iterations.","help":"MAXITER=*number*","type":"value"},{"name":"NUMTRIES=","optional":true,"description":"Specifies the number of times the network is to be trained using a different starting points. Specifying this option helps ensure that the optimizer finds the set of weights that truly minimizes the objective function and does not return a local minimum. The value of number must be an integer between 1 and 99,999. The default is 5.","help":"NUMTRIES=*number*","type":"value"},{"name":"OUTMODEL=","optional":true,"description":"Specifies the data set to which to save the model parameters for the trained network. These parameters include the network architecture, input and target variable names and types, and trained weights.","help":"OUTMODEL=*SAS-data-set*","type":"dataSet"},{"name":"VALID=","optional":true,"description":"Specifies that a validation subset not be used to help determine when to stop training. If you specify VALID=_NONE_ in the TRAIN statement, you cannot have a PARTITION statement.","help":"VALID=*_NONE_*","type":"value"}]},{"name":"WEIGHT","description":"If you specify a WEIGHT statement, variable identifies a numeric variable in the input data set that contains the weight to be placed on the prediction error (the difference between the output of the network and the target value specified in the input data set) for each observation during training. If, instead of specifying a variable, you specify the keyword _INVERSE_PRIORS_, the HPNEURAL procedure calculates the weight applied to the prediction error of each nominal target variable as the total number of observations divided by the number of observations whose target class is the same as the current observation (in other words, the inverse of the fraction of the number of times that the target class occurs in the input data set).","help":"WEIGHT &lt;_INVERSE_PRIORS_&gt; ","arguments":[{"name":"_INVERSE_PRIORS_","optional":true,"description":"If, instead of specifying a variable, you specify the keyword _INVERSE_PRIORS_, the HPNEURAL procedure calculates the weight applied to the prediction error of each nominal target variable as the total number of observations divided by the number of observations whose target class is the same as the current observation (in other words, the inverse of the fraction of the number of times that the target class occurs in the input data set).","type":"standalone"}]}],"supportSiteInformation":{"docsetId":"emhpprcref","docsetVersion":"v_003","docsetTargetFile":"emhpprcref_hpneural_toc.htm"}}