{"name":"SCOREACCEL","statements":[{"name":"PROC SCOREACCEL","description":"Publishes, executes, or deletes a model in CAS or an external data source.","help":"PROC SCOREACCEL \n            <SESSREF=session-reference | SESSUUID=\"session-uuid\">;\n\tPUBLISHMODEL \n               required-arguments\n               <publish-model-optional-arguments>;\n            \n\tRUNMODEL \n               required-arguments\n               <run-model-optional-arguments>;\n            \n\tDELETEMODEL \n               required-arguments\n               <delete-model-optional-arguments>;\n         ","arguments":[{"name":"SESSREF=","optional":true,"description":"specifies the name of a CAS session or the universally unique identifier (UUID) of an existing CAS session to which you want to connect. If no option is specified, the automatic CAS session, CASAUTO, is used.","help":"SESSREF=*session-reference* |  SESSUUID=\"*session-uuid*\"","type":"choice","arguments":[{"name":"SESSREF=","description":"specifies the name of a CAS session to which you want to connect.","help":"SESSREF=*session-reference*","type":"value","supportSiteTargetFragment":"n0nx6nqczi10ehn1m7awq0bm5lrw"},{"name":"SESSUUID=","description":"specifies the universally unique identifier (UUID) of an existing CAS session. You must obtain the SESSUUID from the existing session before you can specify it in this option. The engine connects to the session that is identified in the UUID.","help":"SESSUUID=\"*session-uuid*\"","type":"value","supportSiteTargetFragment":"n1sn7mztg1mw36n1htnbysnz6ams"}],"supportSiteTargetFragment":"p0c1zrzum2wqc0n131bios6cj5vn"}],"supportSiteTargetFile":"p1vd98jpf7dve8n1t5q5n7fhn36c.htm"},{"name":"DELETEMODEL","description":"Deletes a model from CAS or an external data source.","help":"DELETEMODEL \n\tCASLIB=\"caslib\"\n\tMODELNAME=\"model-name\"\n\tMODELTABLE=\"model-table\" | \n                     \"caslib.model-table\" | \"schema.model-table\"\n\t<delete-model-optional-arguments>;","arguments":[{"name":"CASLIB=","description":"specifies the name of the caslib that is associated with the data source where the model is published.","help":"CASLIB=\"*casref*\"","type":"value","supportSiteTargetFragment":"p0qdw3u5156jf3n17k887ovrmqom"},{"name":"MODELNAME=","aliases":["MODEL="],"description":"specifies the name of the model to be deleted.","help":"MODELNAME=\"*model-name*\"","type":"value","supportSiteTargetFragment":"n0rchiqyun7l5un1adycgqebfmvh"},{"name":"MODELTABLE=","description":"specifies the name of the table that contains the model to be deleted when deleting a model from CAS or Teradata.","help":"MODELTABLE=\"*model-table*\" | \"*caslib.model-table*\" | \"*schema.model-table*\"","type":"choice","arguments":[{"name":"\"model-table\"","placeholder":true,"type":"dataSet"},{"name":"\"caslib.model-table\"","placeholder":true,"type":"dataSet"},{"name":"\"schema.model-table\"","placeholder":true,"type":"dataSet"}],"supportSiteTargetFragment":"p1ply6svtx48imn1qtj96eqvnbga"},{"name":"AUTHDOMAIN=","optional":true,"description":"specifies the name of the authentication domain that contains the credentials (user name and password) that are used to access Teradata.","help":"AUTHDOMAIN=\"*authentication-domain*\" ","type":"value","supportSiteTargetFragment":"n00gxrul9onyhjn14jd4i4qac6rm"},{"name":"AUTHTOKEN=","optional":true,"description":"specifies the authentication token that is used to establish a connection with a Spark cluster.","help":"AUTHTOKEN=\"*authentication-token*\"","type":"value","supportSiteTargetFragment":"n0sd2isgd8tzw4n10ct0n88gwxm9"},{"name":"CLASSPATH=","optional":true,"description":"specifies the class path used in the Hadoop call context. The class path can be a folder or individual JAR files. The Hadoop configuration folder must be included in the class path.","help":"CLASSPATH=\"*class_path*\"","type":"value","supportSiteTargetFragment":"p1qy9lqyso51unn1lwy5ztup4q9t"},{"name":"CLUSTERID=","optional":true,"description":"specifies the identifier of the Spark cluster.","help":"CLUSTERID=\"*cluster-id*\"","type":"value","supportSiteTargetFragment":"p0qtkdk8n3lc2hn1py8vst6hjedh"},{"name":"DATABASE=","optional":true,"description":"specifies the name of the database.","help":"DATABASE=\"*database-name*\"","type":"value","supportSiteTargetFragment":"p120simq5j2to5n1giz0p5cqazbs"},{"name":"DELETEGLOBAL=","optional":true,"description":"specifies whether the model is deleted from a global model table in CAS.","help":"DELETEGLOBAL=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"deletes the model from the global model table.","type":"standalone","supportSiteTargetFragment":"p0sekcrcy90hxbn1mw87l0m5guui"},{"name":"FALSE","aliases":["NO"],"description":"deletes the model from the model table in the local CAS session, leaving the global table unaltered.","type":"standalone","supportSiteTargetFragment":"n1fe1no97rattwn1m3jv5h3ivhbv"}],"supportSiteTargetFragment":"n1dtn9a0uh4njrn12lt2hk06uu6v"},{"name":"EXTTYPE=","optional":true,"aliases":["TARGET="],"description":"specifies the target environment to which the model is to be deleted.","help":"EXTTYPE=CAS | DATABRICKS | FILESYSTEM | HADOOP | SINGLESTORE | SYNAPSE | TERADATA","type":"choice","arguments":[{"name":"CAS","description":"specifies to delete the model from a model table in CAS.","type":"standalone","supportSiteTargetFragment":"p03rhibwqoay4cn17br5wp8zpyc7"},{"name":"DATABRICKS","description":"specifies to delete the model from Databricks. This value is supported as of 2023.10 to delete a model that was published to a Spark table.","type":"standalone","supportSiteTargetFragment":"n0gm4jmrf2nfiwn1xowu0n29wavq"},{"name":"FILESYSTEM","description":"specifies to delete the model from a cloud-based file system. FILESYSTEM supports Microsoft Azure Data Lake Storage Gen2 (ADLS) and Amazon S3.","type":"standalone","supportSiteTargetFragment":"p1m992v6ehvl79n1qja6panoabdw"},{"name":"HADOOP","description":"specifies to delete the model from the Hadoop server. This value is supported for HDInsight as of 2023.11 to delete a model that was published to a Hive table.","type":"standalone","supportSiteTargetFragment":"p03e0ebj9a0d7zn16ee7foatp0p1"},{"name":"SINGLESTORE","description":"specifies to delete the model from the SingleStore cluster. This value is supported as of 2023.05.","type":"standalone","supportSiteTargetFragment":"n0xkxbjwzg7q0fn1ia90cqv1b944"},{"name":"SYNAPSE","description":"specifies to delete the model from Azure Synapse. This value is supported as of 2023.12 to delete a model that was published to an SQL Server table.","type":"standalone","supportSiteTargetFragment":"n07muvprymsb39n1mzor3m2s02lv"},{"name":"TERADATA","description":"specifies to delete the model from a model table in the Teradata database.","type":"standalone","supportSiteTargetFragment":"p13a2morl60i2un1k1x0zpn59fw0"}],"supportSiteTargetFragment":"p0s5el7e8893w3n112q55q6n2xol"},{"name":"MODELDATABASE=","optional":true,"description":"specifies the database where the model is stored.","help":"MODELDATABASE=\"*model-database*\"","type":"value","supportSiteTargetFragment":"n1io117mhrovzin1brhjnmr66xso"},{"name":"MODELDIR=","optional":true,"description":"specifies the root folder where the model directory is stored.","help":"MODELDIR=\"*model-directory*\"","type":"value","supportSiteTargetFragment":"n0mfpgdi1u16tan1o5ax1hid5tlj"},{"name":"MODELSCHEMA=","optional":true,"description":"specifies the schema for the stored model.","help":"MODELSCHEMA=\"*model-schema*\"","type":"value","supportSiteTargetFragment":"n1s3dnd8hyowe2n12y5qjk4lyyed"},{"name":"PASSWORD=","optional":true,"aliases":["PASS=","PASSWD=","PWD="],"description":"is the password for the user ID on ADLS, the Hadoop server, or the Teradata server. On ADLS this is value known as the secret.","help":"PASSWORD=\"*password*\"","type":"value","supportSiteTargetFragment":"p1advdivfjtusgn16qkqtu94r0jc"},{"name":"PERSISTTABLE=","optional":true,"description":"specifies whether the updated model table, that results from deleting a model, should be saved to the caslib data source associated with the table.","help":"PERSISTTABLE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"saves the updated model table to the data source.","type":"standalone","supportSiteTargetFragment":"p068mznq0b46wen1pjdy69d0qd10"},{"name":"FALSE","aliases":["NO"],"description":"does not save the updated model table to the data source.","type":"standalone","supportSiteTargetFragment":"n0yk2j7w66r7men1lsjbarlmiuuy"}],"supportSiteTargetFragment":"n0n517iuvmynxnn1sy9tei9v0w2k"},{"name":"PROMOTETABLE=","optional":true,"description":"specifies whether the updated model table, that results from deleting a model, should be promoted to global scope on the CAS server.","help":"PROMOTETABLE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"promotes the updated model table to global scope.","type":"standalone","supportSiteTargetFragment":"p032xd0ahfob9xn18qzdngf9w2cr"},{"name":"FALSE","aliases":["NO"],"description":"does not promote the updated model table to global scope.","type":"standalone","supportSiteTargetFragment":"p04qyfm10mb2hqn1m5x1non8a5pd"}],"supportSiteTargetFragment":"p1g5baz4m6wvxon1ujvmx3pbjbe0"},{"name":"REPLACETABLE=","optional":true,"description":"specifies whether to allow an existing model table, that results from deleting a model, to be replaced when the updated model table is saved to the caslib data source.","help":"REPLACETABLE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"replaces the model table.","type":"standalone","supportSiteTargetFragment":"p1elk9wfflhljbn1onvdl1lrf7qf"},{"name":"FALSE","aliases":["NO"],"description":"does not replace the model table.","type":"standalone","supportSiteTargetFragment":"n1tcoizf2xnu3xn1skyksgf8ctss"}],"supportSiteTargetFragment":"p1ftts7921fi09n1lhj1mj7fwycs"},{"name":"SCHEMA=","optional":true,"description":"specifies the name of the database or schema.","help":"SCHEMA=\"*schema-name*\"","type":"value","supportSiteTargetFragment":"p00uxs035oqfdrn1sumwogbhxbnv"},{"name":"SERVER=","optional":true,"description":"specifies the name of the Teradata server.","help":"SERVER=\"*server*\"","type":"value","supportSiteTargetFragment":"n174xzay7wpx5bn11q4qt5yw7f9a"},{"name":"TIMEOUT=","optional":true,"description":"specifies the number of seconds for the procedure to attempt an operation.","help":"TIMEOUT=\"*n*\"","type":"value","supportSiteTargetFragment":"p00mmlv6dme004n1gc1h6qmylpi5"},{"name":"USERNAME=","optional":true,"aliases":["USER=","USERID=","UID="],"description":"is an authorized user ID on the Hadoop or Teradata server.","help":"USERNAME=\"*id*\"","type":"value","supportSiteTargetFragment":"n1ggldha3044i0n14vegf8zceum5"},{"name":"WEBHDFSURL=","optional":true,"description":"specifies the URL used to access the Hadoop distributed file system through the REST API.","help":"WEBHDFSURL=\"*webhdfs-url*\"","type":"value","supportSiteTargetFragment":"n0p9td5hb4t979n11kq96t7a9yv8"}],"supportSiteTargetFile":"n13m5zjk09bap8n16rjiey5sa8iq.htm"},{"name":"PUBLISHMODEL","description":"Publishes a model in CAS or an external data source.","help":"PUBLISHMODEL \n\tCASLIB=\"caslib\"\n\tMODELNAME=\"model-name\"                      \n\tMODELTABLE=\"model-table\" | \n                     \"caslib.model-table\" | \"schema.model-table\"\n\t\n                  PROGRAMFILE=\"file-path\" |                             fileref\n                  \n\t\n                  <publish-model-optional-arguments>                   ;","arguments":[{"name":"CASLIB=","description":"specifies the name of the caslib that is associated with the data source where the model is published.","help":"CASLIB=\"*casref*\"","type":"value","supportSiteTargetFragment":"p0qdw3u5156jf3n17k887ovrmqoma"},{"name":"MODELNAME=","aliases":["MODEL="],"description":"specifies the name of the model to be published.","help":"MODELNAME=\"*model-name*\"","type":"value","supportSiteTargetFragment":"p0defhhg86o1bon1julunesctz64"},{"name":"MODELTABLE=","description":"specifies the name of the table to which the model is published in CAS or Teradata.","help":"MODELTABLE=\"*model-table*\" | \"*caslib.model-table*\" | \"*schema.model-table*\"","type":"choice","arguments":[{"name":"\"model-table\"","placeholder":true,"type":"dataSet"},{"name":"\"caslib.model-table\"","placeholder":true,"type":"dataSet"},{"name":"\"schema.model-table\"","placeholder":true,"type":"dataSet"}],"supportSiteTargetFragment":"n0lkzpzaa68mbln1gp6arlu9p6py"},{"name":"PROGRAMFILE=","description":"specifies the file that contains the model program to be published.","help":"PROGRAMFILE=\"*file-path*\" | *fileref*","type":"choice","arguments":[{"name":"\"file-path\"","placeholder":true,"type":"value"},{"name":"fileref","placeholder":true,"type":"value"}],"supportSiteTargetFragment":"n1rtefxgysl78kn1saqjad39bo30"},{"name":"AUTHDOMAIN=","optional":true,"description":"specifies the name of the authentication domain that contains the credentials (user name and password) that are used to access Teradata.","help":"AUTHDOMAIN=\"*authentication-domain*\" ","type":"value","supportSiteTargetFragment":"n00gxrul9onyhjn14jd4i4qac6rma"},{"name":"AUTHTOKEN=","optional":true,"description":"specifies the authentication token that is used to establish a connection with a Spark cluster.","help":"AUTHTOKEN=\"*authentication-token*\"","type":"value","supportSiteTargetFragment":"n0sd2isgd8tzw4n10ct0n88gwxm9a"},{"name":"CLASSPATH=","optional":true,"description":"specifies the class path used in the Hadoop call context. The class path can be a folder or individual JAR files. The Hadoop configuration folder must be included in the class path.","help":"CLASSPATH=\"*class_path*\"","type":"value","supportSiteTargetFragment":"p1qy9lqyso51unn1lwy5ztup4q9ta"},{"name":"CLUSTERID=","optional":true,"description":"specifies the identifier of the Spark cluster.","help":"CLUSTERID=\"*cluster-id*\"","type":"value","supportSiteTargetFragment":"p0qtkdk8n3lc2hn1py8vst6hjedha"},{"name":"DATABASE=","optional":true,"description":"specifies the name of the database.","help":"DATABASE=\"*database-name*\"","type":"value","supportSiteTargetFragment":"p120simq5j2to5n1giz0p5cqazbsa"},{"name":"EXTTYPE=","optional":true,"aliases":["TARGET="],"description":"specifies the target environment to which the model is published.","help":"EXTTYPE=CAS | DATABRICKS | FILESYSTEM | HADOOP | SINGLESTORE | SYNAPSE | TERADATA","type":"choice","arguments":[{"name":"CAS","description":"specifies to publish to a model table in CAS.","type":"standalone","supportSiteTargetFragment":"n0c89p52sraj1gn1tcnuj477ayqa"},{"name":"DATABRICKS","description":"specifies to publish the model to Databricks. This value is supported as of 2023.10 to publish a model to a Spark table.","type":"standalone","supportSiteTargetFragment":"p1k1psiz2vgktln1b6vqydibo23x"},{"name":"FILESYSTEM","description":"specifies to publish the model to a cloud-based file system. FILESYSTEM supports Microsoft Azure Data Lake Storage Gen2 (ADLS) and Amazon S3.","type":"standalone","supportSiteTargetFragment":"n18cbr9yuk96yxn1d5z6tj3k2xar"},{"name":"HADOOP","description":"specifies to publish the model to the Hadoop server. This value is supported for HDInsight as of 2023.11 to publish a model to a Hive table.","type":"standalone","supportSiteTargetFragment":"n1h6hykn1k5raon1qcgtgs21nlu7"},{"name":"SINGLESTORE","description":"specifies to publish the model to the SingleStore cluster. This value is supported as of 2023.05.","type":"standalone","supportSiteTargetFragment":"n1fed6389lwznqn1poq6tswasaxo"},{"name":"SYNAPSE","description":"specifies to publish the model to Azure Synapse. This value is supported as of 2023.12 to publish a model to an SQL Server table.","type":"standalone","supportSiteTargetFragment":"n1v31ct0gvnhmnn10u6m294p635r"},{"name":"TERADATA","description":"specifies to publish to a model table in the Teradata database.","type":"standalone","supportSiteTargetFragment":"n1kr449axait6in11wr1yl9qn15l"}],"supportSiteTargetFragment":"n1fwptai8df8adn1r1m9etarbbb3"},{"name":"FORMATFILE=","optional":true,"description":"specifies the file that contains the user-defined format XML definition to be published.","help":"FORMATFILE=\"*file-path*\" | *fileref*","type":"choice","arguments":[{"name":"\"file-path\"","placeholder":true,"type":"value"},{"name":"fileref","placeholder":true,"type":"value"}],"supportSiteTargetFragment":"n1dyg7oy2h6gmrn10zdak8ap0ssv"},{"name":"FORMATITEMSTOREFILE=","optional":true,"description":"specifies the file that contains the format item store to be published.","help":"FORMATITEMSTOREFILE=\"*file-path*\" | *fileref*","type":"choice","arguments":[{"name":"\"file-path\"","placeholder":true,"type":"value"},{"name":"fileref","placeholder":true,"type":"value"}],"supportSiteTargetFragment":"p1o3mfrkkuho5kn1pnw9y36gjllt"},{"name":"KEEPLIST=","optional":true,"description":"specifies whether to include a KEEP statement in the DS2 model program that is automatically generated from an analytic store model.","help":"KEEPLIST=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"includes a KEEP statement.","type":"standalone","supportSiteTargetFragment":"p1o1r29whakvjzn1uuirvcaslb8z"},{"name":"FALSE","aliases":["NO"],"description":"does not include a KEEP statement.","type":"standalone","supportSiteTargetFragment":"p1r3x5rqf13pcrn1kjwkeyask6ev"}],"supportSiteTargetFragment":"p1gx7looluwyoyn0zy18ywoadsjc"},{"name":"MODELDATABASE=","optional":true,"description":"specifies the database where the model is stored.","help":"MODELDATABASE=\"*model-database*\"","type":"value","supportSiteTargetFragment":"n1io117mhrovzin1brhjnmr66xsoa"},{"name":"MODELDIR=","optional":true,"description":"specifies the root folder where the model directory is stored.","help":"MODELDIR=\"*model-directory*\"","type":"value","supportSiteTargetFragment":"n0mfpgdi1u16tan1o5ax1hid5tlja"},{"name":"MODELNOTES=","optional":true,"description":"specifies the model notes to be written to the model table.","help":"MODELNOTES=\"*model-notes*\"","type":"value","supportSiteTargetFragment":"p1q3xujukjrzd5n1g3xznnj9mcoj"},{"name":"MODELSCHEMA=","optional":true,"description":"specifies the schema for the stored model.","help":"MODELSCHEMA=\"*model-schema*\"","type":"value","supportSiteTargetFragment":"n1s3dnd8hyowe2n12y5qjk4lyyeda"},{"name":"MODELTYPE=","optional":true,"description":"specifies the type of the input model program.","help":"MODELTYPE=DATASTEP | DS2","type":"choice","arguments":[{"name":"DATASTEP","aliases":["DS"],"description":"specifies that the input model program is DATA step code.","type":"standalone","supportSiteTargetFragment":"n0rjt8hfe5embkn1o51vycqwf9xt"},{"name":"DS2","description":"specifies that the input model program is DS2 code.","type":"standalone","supportSiteTargetFragment":"p1aoyqij16jw9nn1iyaarbqa0trd"}],"supportSiteTargetFragment":"n1id5d7i0zyv10n18qj2aruhdaqg"},{"name":"MODELUUID=","optional":true,"description":"specifies that the Model UUID is written to the model table.","help":"MODELUUID=\"*model-uuid*\"","type":"value","supportSiteTargetFragment":"n1renrofh137s0n1v2drwtuf42wc"},{"name":"OUTDIR=","optional":true,"description":"specifies the local output directory that contains the program file that was converted from DATA step to DS2.","help":"OUTDIR=\"*work-directory*\"","type":"value","supportSiteTargetFragment":"n0kc52jso6we20n184xj8i4rklwd"},{"name":"PASSWORD=","optional":true,"aliases":["PASS=","PASSWD=","PWD="],"description":"is the password for the user ID on ADLS, the Hadoop server, or the Teradata server. On ADLS this is value known as the secret.","help":"PASSWORD=\"*password*\"","type":"value","supportSiteTargetFragment":"p1advdivfjtusgn16qkqtu94r0jca"},{"name":"PERSISTTABLE=","optional":true,"description":"specifies whether the updated model table should be saved to the caslib data source associated with the table.","help":"PERSISTTABLE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"saves the updated model table to the data source.","type":"standalone","supportSiteTargetFragment":"n08kwjp2un6i5jn1qi3zclfnqe9t"},{"name":"FALSE","aliases":["NO"],"description":"does not save the updated model table to the data source.","type":"standalone","supportSiteTargetFragment":"n1maqhkhx16vmhn1al48tbxystrj"}],"supportSiteTargetFragment":"p0hmly1zl5tuwcn14kamtchltcs7"},{"name":"PROMOTETABLE=","optional":true,"description":"specifies whether the updated model table should be promoted to global scope on the CAS server.","help":"PROMOTETABLE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"promotes the updated model table to global scope.","type":"standalone","supportSiteTargetFragment":"n1q9rrrrbd2vc4n11y38j8l5wupd"},{"name":"FALSE","aliases":["NO"],"description":"does not promote the updated model table to global scope.","type":"standalone","supportSiteTargetFragment":"p0bhay95j3rmrin1cbzxpy94vuny"}],"supportSiteTargetFragment":"n1vu2k9l4qzey4n157ol2xupdn1q"},{"name":"PUBLISHGLOBAL=","optional":true,"description":"specifies whether the model is published to a global model table in CAS.","help":"PUBLISHGLOBAL=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"","type":"standalone","supportSiteTargetFragment":"p0e0pq35fog6m2n1ejr12gbzhf60"},{"name":"FALSE","aliases":["NO"],"description":"publishes the model to the model table in the local CAS session, leaving the global model table unaltered.","type":"standalone","supportSiteTargetFragment":"n0dsopdy38pu50n11fp00xeokkug"}],"supportSiteTargetFragment":"n1eo7wadeyjr2vn12q0yi46lufme"},{"name":"REPLACEMODEL=","optional":true,"description":"specifies whether to allow an existing model in the model table to be replaced by the model being published.","help":"REPLACEMODEL=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"replaces the model in the model table.","type":"standalone","supportSiteTargetFragment":"n1w9h4u5w7b7opn12xyf0pao1422"},{"name":"FALSE","aliases":["NO"],"description":"does not replace the model in the model table.","type":"standalone","supportSiteTargetFragment":"n117rj86d4zs59n17lr54b4eii6z"}],"supportSiteTargetFragment":"n0j04blitrawp4n1vs0f5bzfksit"},{"name":"REPLACETABLE=","optional":true,"description":"specifies whether to allow an existing model table to be replaced when the updated model table is saved to the caslib data source.","help":"REPLACETABLE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"replaces the model table.","type":"standalone","supportSiteTargetFragment":"p03tafh7pu10fan1366d06g5ksrn"},{"name":"FALSE","aliases":["NO"],"description":"does not replace the model table.","type":"standalone","supportSiteTargetFragment":"n0msfu132nkdmbn18yzb0gl00azg"}],"supportSiteTargetFragment":"p1fa4edesvng4sn1esikgus3jcvi"},{"name":"SCHEMA=","optional":true,"description":"specifies the name of the database or schema.","help":"SCHEMA=\"*schema-name*\"","type":"value","supportSiteTargetFragment":"p00uxs035oqfdrn1sumwogbhxbnva"},{"name":"SERVER=","optional":true,"description":"specifies the name of the Teradata server.","help":"SERVER=\"*server*\"","type":"value","supportSiteTargetFragment":"n174xzay7wpx5bn11q4qt5yw7f9aa"},{"name":"STOREFILES=","optional":true,"aliases":["STOREFILE="],"description":"specifies a list of analytic store .sasast files, one for each analytic store to be published. The list of files can be a mixture of file path names and file references.","help":"STOREFILES=(\"file-path-1\" | fileref-1\n                        <,\"file-path-2” | fileref-2,                             ...>)","type":"standaloneOrValue","arguments":[{"name":"\"file-path-1\"","placeholder":true,"type":"value"},{"name":"fileref-1","placeholder":true,"type":"value"}],"supportSiteTargetFragment":"n1v4fuwez6rl4cn15gsezve1gj6s"},{"name":"STORETABLES=","optional":true,"description":"specifies one or more CAS blob table names that contain the analytic stores to be published. Each table must include a VARBINARY column named \"_state_\" that contains the analytic store blob.","help":"STORETABLES=(\"store-table-1\" | \"caslib.store-table-1\"\n                        <,\"store-table-2\" | \"caslib.store-table-2\",                                ...>)","type":"standaloneOrValue","arguments":[{"name":"\"store-table-1\"","placeholder":true,"type":"dataSet"},{"name":"\"caslib.store-table-1\"","placeholder":true,"type":"dataSet"}],"supportSiteTargetFragment":"n1689d9sasf1k3n148xf2fdoil6n"},{"name":"TIMEOUT=","optional":true,"description":"specifies the number of seconds for the procedure to attempt an operation.","help":"TIMEOUT=\"*n*\"","type":"value","supportSiteTargetFragment":"p00mmlv6dme004n1gc1h6qmylpi5a"},{"name":"USERNAME=","optional":true,"aliases":["USER=","USERID=","UID="],"description":"is an authorized user ID on the Hadoop or Teradata server.","help":"USERNAME=\"*id*\"","type":"value","supportSiteTargetFragment":"n1ggldha3044i0n14vegf8zceum5a"},{"name":"VARXMLFILE=","optional":true,"aliases":["XMLFILE="],"description":"specifies the file that contains the variable metadata XML to be used during translation of an input DATA step model program to DS2.","help":"VARXMLFILE=\"*file-path*\" | *fileref*","type":"choice","arguments":[{"name":"\"file-path\"","placeholder":true,"type":"value"},{"name":"fileref","placeholder":true,"type":"value"}],"supportSiteTargetFragment":"p13wa99jkqou80n1auxqoobjaf7v"},{"name":"WEBHDFSURL=","optional":true,"description":"specifies the URL used to access the Hadoop distributed file system through the REST API.","help":"WEBHDFSURL=\"*webhdfs-url*\"","type":"value","supportSiteTargetFragment":"n0p9td5hb4t979n11kq96t7a9yv8a"}],"supportSiteTargetFile":"p1evqpz1p0yakcn12smb6rb5w7tw.htm"},{"name":"RUNMODEL","description":"Runs a model in CAS or an external data source.","help":"RUNMODEL \n\tCASLIB=\"caslib\"\n\t\n                  MODELNAME=\"model-name\"\n\tMODELTABLE=\"model-table\" | \n                        \"caslib.model-table\" | \"schema.model-table\"\n\t<run-model-optional-arguments>;                ","arguments":[{"name":"CASLIB=","description":"specifies the name of the caslib that is associated with the data source where the model is executed.","help":"CASLIB=\"*casref*\"","type":"value","supportSiteTargetFragment":"n0z6ezd2koem87n1473f3467fftp"},{"name":"MODELNAME=","aliases":["MODEL="],"description":"specifies the name of the model to run.","help":"MODELNAME=\"*model-name*\"","type":"value","supportSiteTargetFragment":"n1a6t3uiap1do9n1f08cqojqviy8"},{"name":"MODELTABLE=","description":"specifies the name of the table that contains the model to run.","help":"MODELTABLE=\"*model-table*\" | \"*caslib.model-table*\" | \"*schema.model-table*\"","type":"choice","arguments":[{"name":"\"model-table\"","placeholder":true,"type":"dataSet"},{"name":"\"caslib.model-table\"","placeholder":true,"type":"dataSet"},{"name":"\"schema.model-table\"","placeholder":true,"type":"dataSet"}],"supportSiteTargetFragment":"n0riukzovm3wk7n1w7i6elzfd701"},{"name":"AUTHDOMAIN=","optional":true,"description":"specifies the name of the authentication domain that contains the credentials (user name and password) that are used to access Teradata.","help":"AUTHDOMAIN=\"*authentication-domain*\" ","type":"value","supportSiteTargetFragment":"n00gxrul9onyhjn14jd4i4qac6rmb"},{"name":"AUTHTOKEN=","optional":true,"description":"specifies the authentication token that is used to establish a connection with a Spark cluster.","help":"AUTHTOKEN=\"*authentication-token*\"","type":"value","supportSiteTargetFragment":"n0sd2isgd8tzw4n10ct0n88gwxm9b"},{"name":"CLASSPATH=","optional":true,"description":"specifies the class path used in the Hadoop call context. The class path can be a folder or individual JAR files. The Hadoop configuration folder must be included in the class path if you are not specifying the CONFIGPATH= option.","help":"CLASSPATH=\"*class_path*\"","type":"value","supportSiteTargetFragment":"n1sqb8g4sx3xbfn134la564q0zrl"},{"name":"CLUSTERID=","optional":true,"description":"specifies the identifier of the Spark cluster.","help":"CLUSTERID=\"*cluster-id*\"","type":"value","supportSiteTargetFragment":"p0qtkdk8n3lc2hn1py8vst6hjedhb"},{"name":"CONFIGPATH=","optional":true,"description":"specifies a single folder where all the Hadoop and Spark configuration files reside.","help":"CONFIGPATH=\"*configuration-path*\"","type":"value","supportSiteTargetFragment":"n0bi5zglb1c92vn1k5j9r5vd48od"},{"name":"CUSTOMJAR=","optional":true,"description":"specifies the local JAR file that contains the user-provided custom reader. The custom JAR file is automatically copied to the Hadoop cluster during job submission.","help":"CUSTOMJAR=\"*file-path*\"","type":"value","supportSiteTargetFragment":"n17uqjkdtsgi4in1ayzy1vo7jm8c"},{"name":"DATABASE=","optional":true,"description":"specifies the name of the database.","help":"DATABASE=\"*database-name*\"","type":"value","supportSiteTargetFragment":"n0325klus0yobqn1u3scqqbjhxd2"},{"name":"DBMAXTEXT=","optional":true,"description":"specifies the maximum number of bytes to allocate for STRING data type columns.","help":"DBMAXTEXT=*number-of-bytes*","type":"value","supportSiteTargetFragment":"n0cxho2h63zr9qn19uunehb7s574"},{"name":"EPOPTIONS=","optional":true,"description":"specifies properties that are passed to the SAS Embedded Process.","help":"EPOPTIONS=\"*options-string*\"","type":"value","supportSiteTargetFragment":"p02ygdxwz3ujedn1a4s1ca4pm8oy"},{"name":"EXTTYPE=","optional":true,"aliases":["TARGET="],"description":"specifies the target environment in which the model is to be run.","help":"EXTTYPE=CAS | HADOOP | SINGLESTORE | SPARK | TERADATA","type":"choice","arguments":[{"name":"CAS","description":"specifies to run the model in CAS.","type":"standalone","supportSiteTargetFragment":"p1ekdcnsruzyf6n18dsft656vow2"},{"name":"HADOOP","description":"specifies to run the model using the SAS Embedded Process for Hadoop.","type":"standalone","supportSiteTargetFragment":"n0vpnvwvlqckezn13ghj15zihtp8"},{"name":"SINGLESTORE","description":"specifies to run the model using the SAS Embedded Process for SingleStore. This value is supported as of 2023.05.","type":"standalone","supportSiteTargetFragment":"n15on3a52jc6enn1l35yvebl1aqd"},{"name":"SPARK","description":"specifies to run the model using the SAS Embedded Process for Spark. The CASLIB= option is required. In the caslib use the PLATFORM= option to specify the external target. Databricks and Synapse are supported as of 2021.2.2. HDInsight is supported as of 2023.04. For more information, see .","type":"standalone","supportSiteTargetFragment":"p1eigmwiom2pbcn12226ld8tzxve"},{"name":"TERADATA","description":"specifies to run the model using the SAS Embedded Process for Teradata.","type":"standalone","supportSiteTargetFragment":"n00kfpt9iyz40tn109ggnvwd01ik"}],"supportSiteTargetFragment":"p0il02h134rg89n1a2sl4g7xc27z"},{"name":"FORCEOVERWRITE=","optional":true,"description":"specifies whether to force deletion of the output data directory before running the Hadoop MapReduce job.","help":"FORCEOVERWRITE=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"forces deletion of the output data directory.","type":"standalone","supportSiteTargetFragment":"p148m4qntqwwx8n1c15mog8yxsw1"},{"name":"FALSE","aliases":["NO"],"description":"does not force deletion of the output data directory.","type":"standalone","supportSiteTargetFragment":"p1ojs1j85niscrn13r7cyimdiuy6"}],"supportSiteTargetFragment":"n0eq5o0alvmpswn1hme97kc3bk7y"},{"name":"HIVEPORT=","optional":true,"description":"specifies the Hive server port number.","help":"HIVEPORT=*integer*","type":"value","supportSiteTargetFragment":"n0ipza234hgl19n1xg2xzgryw19c"},{"name":"INDATASET=","optional":true,"description":"specifies the name of the Spark dataset passed as input to the SAS Embedded Process.","help":"INDATASET=\"*input-dataset*\"","type":"dataSet","supportSiteTargetFragment":"p12r6si4zgnwron1ejlqybnb7w36"},{"name":"INHDMD=","optional":true,"description":"specifies the name of the input Spark dataset file on HDFS.","help":"INHDMD=\"*file-path*\"","type":"value","supportSiteTargetFragment":"p1c6fd82vbzoi4n1l8rj3tdkzs60"},{"name":"INQUERY=","optional":true,"description":"specifies an SQL SELECT statement that defines the inputs to the SAS Embedded Process. The SQL query must be supported by the data source.","help":"INQUERY=\"*sql-query*\"","type":"value","supportSiteTargetFragment":"n1cl24x2c4h0irn14elif3mhs7mc"},{"name":"INTABLE=","optional":true,"aliases":["INPUTTABLE="],"description":"specifies the name of the input table.","help":"INTABLE=\"*input-table*\" | \"*caslib.input-table*\" | \"*schema.input-table*\"","type":"choice","arguments":[{"name":"\"input-table\"","placeholder":true,"type":"dataSet"},{"name":"\"caslib.input-table","placeholder":true,"type":"dataSet"},{"name":"\"schema.input-table\"","placeholder":true,"type":"dataSet"}],"supportSiteTargetFragment":"n034pmkkdw499mn1xerozb3d1y5m"},{"name":"JOBMANAGEMENTURL=","optional":true,"aliases":["RESTURL="],"description":"specifies the URL used to submit execution requests over a REST interface to services such as Apache Livy or Databricks Notebooks.","help":"JOBMANAGEMENTURL=\"*rest-url*\"","type":"value","supportSiteTargetFragment":"n0pl2g61xxefkun1w9fsrrkzczgy"},{"name":"KEEPLISTCOLUMNS=","optional":true,"aliases":["KEEPLISTCOLS="],"description":"specifies the name of the column (or columns) to be kept by the DS2 program.","help":"KEEPLISTCOLUMNS=\"column-1\n                        <column-2 ...>\" <br/> KEEPLISTCOLUMNS=(column-1\n                        <column-2 ...>) <br/> KEEPLISTCOLUMNS=(\"column-1\"                               <\"column-2\" ...>)","type":"value","supportSiteTargetFragment":"n11gr0bu6n6q16n11r3m6gzprocz"},{"name":"KEEPLISTFILE=","optional":true,"description":"specifies the name of the file that contains a list of columns to be kept by the DS2 program.","help":"KEEPLISTFILE=\"*file-path*\"","type":"value","supportSiteTargetFragment":"n04gpwfum4dcj4n10z9j9aylcdw3"},{"name":"MODELDATABASE=","optional":true,"description":"specifies the database where the model is stored.","help":"MODELDATABASE=\"*model-database*\"","type":"value","supportSiteTargetFragment":"n1io117mhrovzin1brhjnmr66xsob"},{"name":"MODELDIR=","optional":true,"description":"specifies the root folder where the model directory is stored.","help":"MODELDIR=\"*model-directory*\"","type":"value","supportSiteTargetFragment":"p01yck5mrtqw5in12cnsmx0gunxr"},{"name":"MODELSCHEMA=","optional":true,"description":"specifies the schema for the stored model.","help":"MODELSCHEMA=\"*model-schema*\"","type":"value","supportSiteTargetFragment":"n1s3dnd8hyowe2n12y5qjk4lyyedb"},{"name":"OUTDATASET=","optional":true,"description":"specifies the name of the output Spark dataset to be created by the SAS Embedded Process.","help":"OUTDATASET=\"*output-dataset*\"","type":"dataSet","supportSiteTargetFragment":"n0wfs0q8k3qptcn1bw4tqma36yhc"},{"name":"OUTHDMD=","optional":true,"description":"specifies the name of the output Hadoop metadata file that is created by the SAS Embedded Process.","help":"OUTHDMD=\"*file-path*\"","type":"value","supportSiteTargetFragment":"n1di5f8wonchmwn1908relrs7f6r"},{"name":"OUTKEY=","optional":true,"description":"specifies the name of one or more columns used for the primary index of the output table that is created by the SAS Embedded Process.","help":"OUTKEY=\"column-1\n                        <column-2 ...)>\" <br/> OUTKEY=(column-1\n                        <column-2 ...)> <br/> OUTKEY=(\"column-1\"                               <\"column-2\"                             ...)>","type":"value","supportSiteTargetFragment":"n0uhuzuonyevehn153x94y2e87ti"},{"name":"OUTPUTFOLDER=","optional":true,"description":"specifies the name of the directory where the output files are stored.","help":"OUTPUTFOLDER=\"*directory-path*\"","type":"value","supportSiteTargetFragment":"p1bbxvorn7zrnpn1iixov5lfhqi4"},{"name":"OUTPUTFORMATCLASS=","optional":true,"description":"specifies the name of the output format class in dot notation that is used to write the output records.","help":"OUTPUTFORMATCLASS=\"*class-name*\"","type":"value","supportSiteTargetFragment":"n0ufy5xykzg7cun13fi1ph8vfi4i"},{"name":"OUTRECORDFORMAT=","optional":true,"description":"specifies the format of the output record that is produced by the SAS Embedded Process for Hadoop.","help":"OUTRECORDFORMAT=BINARY | DELIMITED","type":"choice","arguments":[{"name":"BINARY","description":"specifies that the output record is binary.","help":"BINARY ","type":"standalone","supportSiteTargetFragment":"n148vd14fbxbgtn187yblm18wonn"},{"name":"DELIMITED","description":"specifies that the output record is delimited.","type":"standalone","supportSiteTargetFragment":"n056arptnl2e31n0zf4w9zha20ue"}],"supportSiteTargetFragment":"p0fsfrqjdxx0nrn1ix18x9p0ay5u"},{"name":"OUTSCHEMA=","optional":true,"description":"specifies the Hive output data source schema name when running a model.","help":"OUTSCHEMA=\"*output-schema*\"","type":"value","supportSiteTargetFragment":"p0qgbn2x6kinu2n185bvahv3k2wt"},{"name":"OUTTABLE=","optional":true,"aliases":["OUTPUTTABLE="],"description":"specifies the name of the output table.","help":"OUTTABLE=\"*output-table*\" | \"*caslib.output-table*\" | \"*schema.output-table*\"","type":"choice","arguments":[{"name":"\"output-table\"","placeholder":true,"type":"dataSet"},{"name":"\"caslib.output-table","placeholder":true,"type":"dataSet"},{"name":"\"schema.output-table\"","placeholder":true,"type":"dataSet"}],"supportSiteTargetFragment":"n10dta7g4ryacwn1b4nwh5jbre27"},{"name":"OUTTABLEOPTIONS=","optional":true,"description":"provides user-specified options that are appended to the Hive CREATE TABLE statement.","help":"OUTTABLEOPTIONS=\"*options-string*\"","type":"value","supportSiteTargetFragment":"n1fekurnnipx32n0zockbenwoov9"},{"name":"PASSWORD=","optional":true,"aliases":["PASS=","PASSWD=","PWD="],"description":"is the password for the user ID on the Hadoop or Teradata server.","help":"PASSWORD=\"*password*\"","type":"value","supportSiteTargetFragment":"p1oq5bk3xxbh5zn1m76wzbv0ab0h"},{"name":"PLATFORM=","optional":true,"description":"specifies the platform where the SAS Embedded Process for Hadoop is to be executed.","help":"PLATFORM=MAPRED | SPARK","type":"choice","arguments":[{"name":"MAPRED","description":"specifies to run the model in MapReduce.","help":"MAPRED ","type":"standalone","supportSiteTargetFragment":"p1vszkbnaoucsin1hl0ory5f4ls8"},{"name":"SPARK","description":"specifies to run the model in Spark.","type":"standalone","supportSiteTargetFragment":"n1xw6q54twaiozn1evyrtmdnkl3b"}],"supportSiteTargetFragment":"p10rs1ea6w7aoin1mshkwmbpkfmg"},{"name":"PROPERTIES=","optional":true,"description":"specifies a Hadoop configuration property as a name-value pair. For multiple properties, specify a single argument containing a comma-separated list of name-value pairs enclosed in parentheses. Any Hadoop configuration property can be assigned using this option. The PROPERTIES parameter can also be specified multiple times, once for each property.","help":"PROPERTIES=\"*name1=value*\"                               &lt;PROPERTIES=\"*name2=value*\"&gt; <br/> PROPERTIES=(\"*name=value*\"&lt;,                               \"*name=value*\",                             ...&gt;)","type":"value","supportSiteTargetFragment":"n07dz9djrynceen1d2d88c8e37jg"},{"name":"SCHEMA=","optional":true,"description":"specifies the name of the database or schema.","help":"SCHEMA=\"*schema-name*\"","type":"value","supportSiteTargetFragment":"p1n9gzpn6rgjcun117051m0y3car"},{"name":"SENDPROGRAM=","optional":true,"description":"specifies whether the model program source code should be sent back to the client and displayed for the user.","help":"SENDPROGRAM=TRUE | FALSE","type":"choice","arguments":[{"name":"TRUE","aliases":["YES"],"description":"sends the source code back to the client.","type":"standalone","supportSiteTargetFragment":"n1kfxn13pyb3ycn1jn81az3sb40h"},{"name":"FALSE","aliases":["NO"],"description":"does not send the source code back to the client.","type":"standalone","supportSiteTargetFragment":"n12l1a6vt53me9n1wy8f89khwhg2"}],"supportSiteTargetFragment":"p02w9pntsfabgbn1rqysozh7av0a"},{"name":"SERVER=","optional":true,"description":"specifies the name of the Teradata server or Hive server.","help":"SERVER=\"*server*\"","type":"value","supportSiteTargetFragment":"p0bowbvk79e87wn1akf2ifvsqil3"},{"name":"TRACE","optional":true,"description":"runs the SAS Embedded Process for Hadoop with traces on.","type":"standalone","supportSiteTargetFragment":"n002z0uwcn8jl9n17h21p6m51ot2"},{"name":"USERNAME=","optional":true,"aliases":["USER=","USERID=","UID="],"description":"is an authorized user ID on the Hadoop or Teradata server.","help":"USERNAME=\"*id*\"","type":"value","supportSiteTargetFragment":"n1ggldha3044i0n14vegf8zceum5b"},{"name":"VERBOSE","optional":true,"description":"specifies that the SAS Embedded Process provide additional logging information.","type":"standalone","supportSiteTargetFragment":"p096164wni7cw4n1iubl53uuxyv3"}],"supportSiteTargetFile":"n1bwckqsf6fjc9n1kzwr5uh2oikh.htm"}],"interactive":true,"supportSiteInformation":{"docsetId":"proc","docsetVersion":"v_002","docsetTargetFile":"p05rmiw27grg9qn1fpffnyvfeoza.htm"}}