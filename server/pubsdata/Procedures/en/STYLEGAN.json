{"name":"STYLEGAN","statements":[{"name":"PROC STYLEGAN","description":"The STYLEGAN Procedure trains a Style GAN model on images in SAS Viya. PROC STYLEGAN implements the Style GAN version 2 model by using the PyTorch library.","help":"PROC STYLEGAN  IMAGESIZE=number<options>;                 \n\tOPTIMIZATION <options>;                 \n\tOUTPUT  OUT=libref.data-table;                 \n\tSAVESTATE  RSTORE=libref.data-table;                 \n\tTRAIN <options>;                 ","arguments":[{"name":"IMAGESIZE=","description":"specifies the image size (width of square images in pixels) in the training data","help":"IMAGESIZE=*number*","type":"value"},{"name":"DATA=","optional":true,"description":"names the input data table for PROC STYLEGAN to use","help":"DATA=*libref.data-table*","type":"dataSet"},{"name":"DETERMINISTIC","optional":true,"description":"DETERMINISTIC} tells the NVIDIA CUDA Deep Neural Network library (cuDNN) that you want only the deterministic implementations","type":"standalone"},{"name":"NUMSAMPLES=","optional":true,"description":"specifies the number of sample images to generate","help":"NUMSAMPLES=*number*","type":"value"},{"name":"SCORESEED=","optional":true,"description":"specifies the seed to use for the random number generator for scoring","help":"SCORESEED=*number*","type":"value"},{"name":"SEED=","optional":true,"description":"specifies the seed to use for the random number generator for training","help":"SEED=*number*","type":"value"},{"name":"USEGPU","optional":true,"description":"specifies that a GPU device is to be used","help":"USEGPU(*suboptions*)","type":"value","arguments":[{"name":"DEVICE=","description":"specifies the ID number of the GPU device that is to be used","help":"DEVICE=*id-number*","type":"value"}]}]},{"name":"OPTIMIZATION","description":"specifies the optimizer parameters to use in training the style GAN model","help":"OPTIMIZATION &lt;options&gt;;                                              ","arguments":[{"name":"ADAM","optional":true,"description":"specifies the optimization method to use in training the GAN model","help":"ADAM (BETA1=*number* BETA2=*number*)","type":"value","arguments":[{"name":"BETA1=","description":"specifies the exponential decay rate for the first-moment estimates","help":" BETA1=*number*","type":"value"},{"name":"BETA2=","description":"specifies the exponential decay rate for the second-moment estimates","help":" BETA2=*number*","type":"value"}]},{"name":"LEARNINGRATE=","optional":true,"description":"specifies the learning rate for the optimizer","help":" LEARNINGRATE=*number*","type":"value"},{"name":"MINIBATCHSIZE=","optional":true,"description":"specifies the number of images in one minibatch","help":" MINIBATCHSIZE=*number*","type":"value"},{"name":"NUMITERS=","optional":true,"description":"specifies the number of minibatches to be used for training the GAN model","help":" NUMITERS=*number*","type":"value"}]},{"name":"OUTPUT","description":"creates an output data table that contains the results of PROC STYLEGAN","help":"OUTPUT  OUT=*libref.data-table*;                                              ","arguments":[{"name":"OUT=","optional":true,"description":"specifies the output table in which to store the generated images from the trained model","help":"OUT=*libref.data-table*","type":"dataSet"}]},{"name":"SAVESTATE","description":"creates an analytic store for the model and saves it as a binary object in a data table","help":"SAVESTATE  RSTORE=*libref.data-table*;                                              ","arguments":[{"name":"RSTORE=","description":"specifies a data table in which to save the analytic store for the model","help":"RSTORE=*libref.data-table*","type":"dataSet"}]},{"name":"TRAIN","description":"specifies the training parameters to use for training the style GAN model","help":"TRAIN &lt;options&gt;;                                              ","arguments":[{"name":"CHECKPOINTFREQ=","optional":true,"description":"specifies the frequency at which to save a checkpoint during the training","help":"CHECKPOINTFREQ=*integer*","type":"value"},{"name":"CHECKPOINTIN=","optional":true,"description":"specifies the checkpoint table to be loaded to restore your model","help":"CHECKPOINTIN=*libref.data-table*","type":"dataSet"},{"name":"CHECKPOINTOUT=","optional":true,"description":"specifies the table in which to save the current model as a checkpoint","help":"CHECKPOINTOUT=*libref.output-table*","type":"dataSet"},{"name":"NTRUNCATIONLATENTS=","optional":true,"description":"specifies the number of latents to use in calculating the truncation mean","help":"NTRUNCATIONLATENTS=*integer*","type":"value"},{"name":"PRINTFREQ=","optional":true,"description":"specifies the frequency at which to print losses to the log and the iteration history table","help":"PRINTFREQ=*integer*","type":"value"},{"name":"REGDFREQ=","optional":true,"description":"specifies the frequency at which to regularize the discriminator","help":"REGDFREQ=*integer*","type":"value"},{"name":"REGGFREQ=","optional":true,"description":"specifies the frequency at which to regularize the generator","help":"REGGFREQ=*integer*","type":"value"},{"name":"REGPATHWEIGHT=","optional":true,"description":"specifies the weight for regularizing the path length loss","help":"REGPATHWEIGHT=*number*","type":"value"},{"name":"REGR1WEIGHT=","optional":true,"description":"specifies the weight for regularizing the R1 loss","help":"REGR1WEIGHT=*number*","type":"value"},{"name":"TRUNCATION=","optional":true,"description":"specifies the truncation ratio for image generation","help":"TRUNCATION=*number*","type":"value"},{"name":"USESMALLNETWORK","optional":true,"description":"USESMALLNETWORK} specifies that small networks are to be used","type":"standalone"}]}],"supportSiteInformation":{"docsetId":"casml","docsetVersion":"latest","docsetTargetFile":"casml_stylegan_toc.htm"}}