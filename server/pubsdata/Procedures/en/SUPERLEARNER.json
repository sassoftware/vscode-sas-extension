{"name":"SUPERLEARNER","statements":[{"name":"PROC SUPERLEARNER","description":"invokes the procedure","help":"PROC SUPERLEARNER <options>;                 \n\tBASELEARNER  'name' model-type<(model-options)><input-options>;                 \n\tCROSSVALIDATION <options>;                 \n\tINPUT  variables </option>;                 \n\tMARGIN  'name' variable='value' <...variable='value'>;                 \n\tOUTPUT  OUT=libref.data-table<options>;                 \n\tSTORE <OUT=>libref.data-table;                 \n\tTARGET  variable </option>;                 ","arguments":[{"name":"APPLYROWORDER","optional":true,"description":"uses group and order information from the input data table","type":"standalone"},{"name":"DATA=","optional":true,"description":"names the input data table for PROC SUPERLEARNER to use","help":"DATA=*libref.data-table*","type":"dataSet"},{"name":"METHOD=","optional":true,"description":"specifies the meta-learning method to be used to estimate the coefficients of the super learner model","help":"METHOD=CCLOGLIK|CCLS|CVSELECTOR","type":"choice"},{"name":"RESTORE=","optional":true,"description":"specifies the name of the item store that contains a model that is fitted and stored from a previous analysis","help":"RESTORE=*libref.data-table*","type":"dataSet"},{"name":"SEED=","optional":true,"description":"specifies the initial seed to start the pseudorandom number generator for k-fold partitioning and base learner model building, where n is an integer","help":"SEED=*n*","type":"value"}]},{"name":"BASELEARNER","description":"provides options for you to specify and customize a base learner model. You must first specify a unique name for the base learner in single quotes","help":"BASELEARNER  'name' *model-type*&lt;(*model-options*)&gt;&lt;input-options&gt;;                                              ","arguments":[{"name":"BART","optional":true,"description":"specifies a Bayesian additive regression trees model","type":"standalone","arguments":[{"name":"MINLEAFSIZE=","description":"specifies the minimum number of observations that each child of a split must contain in the training data in order for the split to be considered","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"NBI=","description":"specifies the number of burn-in iterations to perform before the procedure starts to save samples for prediction","help":"NBI=*number*","type":"value"},{"name":"NBINS=","description":"specifies the number of bins to use for binning the continuous input variables","help":"NBINS=*number*","type":"value"},{"name":"NMC=","description":"specifies the number of iterations in the main simulation loop","help":"NMC=*number*","type":"value"},{"name":"NTHIN=","description":"specifies the thinning rate of the simulation","help":"NTHIN=*number*","type":"value"},{"name":"NTREE=","description":"specifies the number of trees in a sample of the sum-of-trees ensemble","help":"NTREE=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"BNET","optional":true,"description":"specifies a Bayesian network model","type":"standalone","arguments":[{"name":"ALPHA=","description":"specifies the significance level for independence tests by using the chi-square or G-square statistics, where number is between 0 and 1, inclusive","help":"ALPHA=*number*","type":"value"},{"name":"INDEPTEST=","description":"specifies the method to use for independence tests","help":"INDEPTEST=*keyword*","type":"value"},{"name":"MAXPARENTS=","description":"specifies the maximum number of parents that are allowed for each node in the network structure, where integer is a value between 1 and 16, inclusive","help":"MAXPARENTS=*integer*","type":"value"},{"name":"MIALPHA=","description":"specifies the threshold for independence tests by using mutual information, where number is a value between 0 and 1, inclusive","help":"MIALPHA=*number*","type":"value"},{"name":"NUMBIN=","description":"specifies the number of binning levels for all interval variables, where integer is a value between 2 and 1,024, inclusive","help":"NUMBIN=*integer*","type":"value"},{"name":"PARENTING=","description":"specifies the algorithm to use for orienting the network structure","help":"PARENTING=*keyword*","type":"value"},{"name":"PRESCREENING=","description":"specifies the initial screening for the input variables","help":"PRESCREENING=*keyword*","type":"value"},{"name":"STRUCTURE=","description":"specifies the network structure","help":"STRUCTURE=*keyword*","type":"value"},{"name":"VARSELECT=","description":"specifies how input variables are selected beyond the prescreening","help":"VARSELECT=*keyword*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"FACTMAC","optional":true,"description":"specifies a factorization machine model","type":"standalone","arguments":[{"name":"LEARNSTEP=","description":"specifies the learning step size for the stochastic gradient descent algorithm, where number is a positive real number","help":"LEARNSTEP=*number*","type":"value"},{"name":"MAXITER=","description":"specifies the maximum number of iterations for the algorithm to perform, where number is an integer greater than or equal to 1","help":"MAXITER=*number*","type":"value"},{"name":"NFACTORS=","description":"specifies the number of factors to estimate for the model, where number is an integer greater than or equal to 1","help":"NFACTORS=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"FOREST","optional":true,"description":"specifies a forest model","type":"standalone","arguments":[{"name":"INBAGFRACTION=","description":"specifies the fraction of the random bootstrap sample of the training data to be used to grow each tree in the forest, where number is a value between 0 and 1, inclusive","help":"INBAGFRACTION=*number*","type":"value"},{"name":"MAXDEPTH=","description":"specifies the maximum depth of the tree to be grown","help":"MAXDEPTH=*number*","type":"value"},{"name":"MINLEAFSIZE=","description":"specifies the minimum number of observations that each child of a split must contain in the training data table in order for the split to be considered","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"NTREES=","description":"specifies the number of trees to grow in the forest model","help":"NTREES=*number*","type":"value"},{"name":"NUMBIN=","description":"specifies the number of bins to use for binning the interval input variables","help":"NUMBIN=*number*","type":"value"},{"name":"VARS_TO_TRY=","description":"specifies the number of input variables to consider splitting on in a node, where m ranges from 1 to the number of input variables","help":"VARS_TO_TRY=*m*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"GAMMOD","optional":true,"description":"specifies a generalized additive model based on low-rank regression splines","type":"standalone","arguments":[{"name":"CLASS=","description":"names the classification variables to be used as explanatory variables in the analysis if they are also used in the PARAM(effects) option","help":"CLASS=(*variables*)","type":"value"},{"name":"PARAM","description":"specifies parametric effects that are constructed from variables in the input data; this option can appear multiple times","help":"PARAM(*effects*)","type":"value"},{"name":"SPLINE","description":"specifies nonparametric spline effects that are constructed from variables in the input data","help":"SPLINE(*variable*...&lt;*variable*&gt;&lt;/*spline-options*&gt;)","type":"value","arguments":[{"name":"DF=","description":"specifies a fixed degrees of freedom","help":"DF=*n*","type":"value"},{"name":"M=","description":"specifies the order of the derivative in the penalty term, where n is a positive integer","help":"M=*n*","type":"value"}]}]},{"name":"GAMSELECT","optional":true,"description":"specifies a generalized additive model with model selection","type":"standalone","arguments":[{"name":"PARTBYFRAC","description":"randomly assigns specified proportions of the observations in the input data table to the validation role","help":"PARTBYFRAC(VALIDATE=*fraction*)","type":"value"},{"name":"PARTBYVAR=","description":"names the variable in the input data table whose values are used to assign the validation role to each observation","help":"PARTBYVAR=*variable*(VALIDATE=*'value'*)","type":"value"},{"name":"SELECTION=","description":"specifies the method to be used to select the model","help":"SELECTION=*method*&lt;(*method-options*)&gt;","type":"value","arguments":[{"name":"CHOOSE=","description":"specifies the criterion to use in selecting the final model","help":"CHOOSE=VALIDATE","type":"value"},{"name":"MAXITER=","description":"specifies the maximum number of iterations for the boosting method","help":"MAXITER=*number*","type":"value"},{"name":"STEPSIZE=","description":"specifies the step size to use for the boosting algorithm, where number is a value between 0 and 1","help":"STEPSIZE=*number*","type":"value"},{"name":"LAMBDA1=","description":"sets a fixed nonnegative value to control the sparsity penalty","help":"LAMBDA1=*number*","type":"value"},{"name":"LAMBDA2=","description":"sets a fixed nonnegative value to control the smoothness penalty","help":"LAMBDA2=*number*","type":"value"},{"name":"MAXITER=","description":"specifies the maximum number of iterations that generalized additive model fitting can perform by solving reweighted additive models at each iteration","help":"MAXITER=*number*","type":"value"}]},{"name":"CLASS=","description":"names the classification variables to be used as explanatory variables in the analysis if they are also used in the PARAM(effects) option","help":"CLASS=(*variables*)","type":"value"},{"name":"PARAM","description":"specifies parametric effects that are constructed from variables in the input data; you can specify this option multiple times","help":"PARAM(*effects*)","type":"value"},{"name":"SPLINE","description":"specifies nonparametric spline effects that are constructed from variables in the input data","help":"SPLINE(*variable*&lt;*variable*&gt;&lt;*/ spline-options*&gt;)","type":"value","arguments":[{"name":"DEGREE=","description":"specifies the degree of the spline transformation, where n is a nonnegative integer","help":"DEGREE=*n*","type":"value"},{"name":"DF=","description":"specifies the fixed degrees of freedom for the spline at each boosting iteration","help":"DF=*n*","type":"value"}]}]},{"name":"GPCLASS","optional":true,"description":"specifies a Gaussian process classification model","type":"standalone","arguments":[{"name":"KERNEL=","description":"specifies the kernel-related parameters to use in the Gaussian process","help":"KERNEL=*keyword*&lt;(*kernel-options*)&gt;","type":"value","arguments":[{"name":"CONSTANT=","description":"specifies the constant in the linear kernel function","help":"CONSTANT=*n*","type":"value"},{"name":"SIGMA=","description":"specifies the bandwidth in the Gaussian kernel function","help":"SIGMA=*n*","type":"value"}]},{"name":"MAXITER=","description":"specifies the maximum number of Newton iterations","help":"MAXITER=*number*","type":"value"},{"name":"MINLEAFSIZE=","description":"specifies the minimum change of the loss function between consecutive Newton iterations","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"}]},{"name":"GPREG","optional":true,"description":"specifies a Gaussian process regression model","type":"standalone","arguments":[{"name":"ALGORITHM=","description":"specifies the optimization-algorithm to use during training","help":"ALGORITHM=*keyword*","type":"value"},{"name":"AUTORELEVANCEDETERMINATION","description":"uses automatic relevance determination in the kernel function","type":"standalone"},{"name":"JITTERMAXITERS=","description":"specifies the maximum number of iterations for jitter Cholesky decomposition","help":"JITTERMAXITERS=*number*","type":"value"},{"name":"KERNEL=","description":"specifies the kernel-related parameters to be used in the Gaussian process","help":"KERNEL=*keyword*","type":"value"},{"name":"LEARNINGRATE=","description":"specifies the learning rate parameter for the adam or SGD algorithm","help":"LEARNINGRATE=*number*","type":"value"},{"name":"MINIBATCHSIZE=","description":"specifies the size of the minibatches to use in the adam or SGD algorithm","help":"MINIBATCHSIZE=*number*","type":"value"},{"name":"MOMENTUM=","description":"specifies the momentum, where number is a value between 0 and 1, inclusive","help":"MOMENTUM=*number*","type":"value"},{"name":"NINDUCINGPOINTS=","description":"specifies the number of inducing points to use in the sparse Gaussian process, where number is a positive integer","help":"NINDUCINGPOINTS=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"}]},{"name":"GRADBOOST","optional":true,"description":"specifies a gradient boosting model","type":"standalone","arguments":[{"name":"LASSO=","description":"specifies the L1 norm regularization parameter, where number must be nonnegative","help":"LASSO=*number*","type":"value"},{"name":"LEARNINGRATE=","description":"specifies the learning rate for the gradient boosting algorithm, where number is a value between 0 and 1, inclusive","help":"LEARNINGRATE=*number*","type":"value"},{"name":"MAXDEPTH=","description":"specifies the maximum depth of the tree to be grown","help":"MAXDEPTH=*number*","type":"value"},{"name":"MINLEAFSIZE=","description":"specifies the minimum number of observations that each child of a split must contain in the training data table in order for the split to be considered","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"NTREES=","description":"specifies the number of trees to grow in the gradient boosting model","help":"NTREES=*number*","type":"value"},{"name":"NUMBIN=","description":"specifies the number of bins to use for binning the interval input variables","help":"NUMBIN=*number*","type":"value"},{"name":"RIDGE=","description":"specifies the L2 norm regularization parameter, where number must be nonnegative","help":"RIDGE=*number*","type":"value"},{"name":"SAMPLINGRATE=","description":"specifies the fraction of the training data to be used to grow each tree in the boosting model","help":"SAMPLINGRATE=*number*","type":"value"},{"name":"VARS_TO_TRY=","description":"specifies the number of input variables to consider splitting on in a node, where m ranges from 1 to the number of input variables","help":"VARS_TO_TRY=*m*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"LIGHTGRADBOOST","optional":true,"description":"specifies a light gradient boosting machine model","type":"standalone","arguments":[{"name":"BAGGINGFRACTION=","description":"randomly selects a portion of the observations without resampling","help":"BAGGINGFRACTION=*number*","type":"value"},{"name":"BAGGINGFREQUENCY=","description":"specifies the frequency of bagging","help":"BAGGINGFREQUENCY=*number*","type":"value"},{"name":"INPUTFRACTION=","description":"randomly selects a subset of features on each iteration or tree","help":"INPUTFRACTION=*number*","type":"value"},{"name":"LASSO=","description":"specifies the L1-norm regularization parameter, where number must be nonnegative","help":"LASSO=*number*","type":"value"},{"name":"LEAFSIZE=","description":"specifies the minimum number of observations that each child of a split must contain in the training data table in order for the split to be considered","help":"LEAFSIZE=*number*","type":"value"},{"name":"LEARNINGRATE=","description":"specifies the learning rate for each tree, where number must be greater than 0","help":"LEARNINGRATE=*number*","type":"value"},{"name":"MAXDEPTH=","description":"limits the maximum depth of the tree model","help":"MAXDEPTH=*number*","type":"value"},{"name":"MAXITERS=","description":"specifies the maximum number of iterations for the boosting","help":"MAXITERS=*number*","type":"value"},{"name":"NUMBIN=","description":"specifies the number of bins to use for binning the interval input variables","help":"NUMBIN=*number*","type":"value"},{"name":"RIDGE=","description":"specifies the L2-norm regularization parameter, where number must be nonnegative","help":"RIDGE=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"LOGSELECT","optional":true,"description":"specifies a logistic regression model with model selection","type":"standalone","arguments":[{"name":"LASSORHO=","description":"specifies the base regularization parameter for the LASSO model selection method","help":"LASSORHO=*r*","type":"value"},{"name":"LASSOSTEPS=","description":"specifies the maximum number of steps for LASSO model selection","help":"LASSOSTEPS=*n*","type":"value"},{"name":"LASSOTOL=","description":"specifies the convergence tolerance for the optimization algorithm that solves for the LASSO parameter estimates at each step of LASSO model selection","help":"LASSOTOL=*r*","type":"value"},{"name":"LINK=","description":"specifies the link function for the model","help":"LINK=*keyword*","type":"value"},{"name":"PARTBYFRAC","description":"randomly assigns specified proportions of the observations in the input data table to the validation role","help":"PARTBYFRAC(VALIDATE=*fraction*)","type":"value"},{"name":"PARTBYVAR=","description":"names the variable in the input data table whose values are used to assign the validation role to each observation","help":"PARTBYVAR=*variable*(VALIDATE=*'value'*)","type":"value"},{"name":"SELECTION=","description":"specifies the method to be used to select the model","help":"SELECTION=*method*&lt;(*method-options*)&gt;","type":"value"},{"name":"CLASS=","description":"names the classification variables to be used as explanatory variables in the analysis if you also specify them in the EFFECT= option","help":"CLASS=(*variables*)","type":"value"},{"name":"EFFECT=","description":"specifies model effects that are constructed from variables in the input data table","help":"EFFECT=(*effects*)","type":"value"}]},{"name":"REGSELECT","optional":true,"description":"specifies an ordinary least squares regression model with model selection","type":"standalone","arguments":[{"name":"PARTBYFRAC","description":"randomly assigns specified proportions of the observations in the input data table to the validation role","help":"PARTBYFRAC(VALIDATE=*fraction*)","type":"value"},{"name":"PARTBYVAR=","description":"names the variable in the input data table whose values are used to assign the validation role to each observation","help":"PARTBYVAR=*variable*(VALIDATE=*'value'*)","type":"value"},{"name":"SELECTION=","description":"specifies the method to be used to select the model","help":"SELECTION=*method*&lt;(*method-options*)&gt;","type":"value"},{"name":"CLASS=","description":"names the classification variables to be used as explanatory variables in the analysis if you also specify them in the EFFECT= option","help":"CLASS=(*variables*)","type":"value"},{"name":"EFFECT=","description":"specifies model effects that are constructed from variables in the input data table","help":"EFFECT=(*effects*)","type":"value"}]},{"name":"SVMACHINE","optional":true,"description":"specifies a support vector machine model","type":"standalone","arguments":[{"name":"C=","description":"specifies the penalty value, where number is a real number greater than 0","help":"C=*number*","type":"value"},{"name":"DEGREE=","description":"specifies the degree that is used in a polynomial kernel","help":"DEGREE=*number*","type":"value"},{"name":"EPSILON=","description":"specifies the insensitive loss value, where number is a nonnegative real number","help":"EPSILON=*number*","type":"value"},{"name":"KERNEL=","description":"specifies the type of kernel","help":"KERNEL=*keyword*","type":"value"},{"name":"METHOD=","description":"specifies the optimization method","help":"METHOD=*keyword*","type":"value"},{"name":"RBFPARAMETER=","description":"specifies the K_PAR parameter that is used in an RBF kernel, where number is greater than or equal to 0.0001","help":"RBFPARAMETER=*number*","type":"value"},{"name":"REGL2=","description":"specifies the L2 penalty value when METHOD=CD, where number is a real number greater than 0","help":"REGL2=*number*","type":"value"},{"name":"SIGMOIDPARAMETER1=","description":"specifies the K_PAR1 parameter that is used in a sigmoid kernel, where number is a positive number","help":"SIGMOIDPARAMETER1=*number*","type":"value"},{"name":"SIGMOIDPARAMETER2=","description":"specifies the K_PAR2 parameter that is used in a sigmoid kernel, where number is a real number","help":"SIGMOIDPARAMETER2=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]},{"name":"TREESPLIT","optional":true,"description":"specifies a tree-based statistical model","type":"standalone","arguments":[{"name":"CRITERION=","description":"specifies the criterion by which to split a parent node into child nodes","help":"CRITERION=*keyword*","type":"value"},{"name":"DEGREE=","description":"specifies the maximum depth of the tree to be grown","help":"DEGREE=*number*","type":"value"},{"name":"MINLEAFSIZE=","description":"specifies the minimum number of observations per child node","help":"MINLEAFSIZE=*number*","type":"value"},{"name":"NUMBIN=","description":"specifies the number of bins to use for binning interval predictor variables","help":"NUMBIN=*number*","type":"value"},{"name":"INTINPUT=","description":"specifies the interval input variables for the base learner model","help":"INTINPUT=(*variables*)","type":"value"},{"name":"NOMINPUT=","description":"specifies the nominal input variables for the base learner model","help":"NOMINPUT=(*variables*)","type":"value"}]}]},{"name":"CROSSVALIDATION","description":"controls details about the k-fold cross-validation process","help":"CROSSVALIDATION &lt;options&gt;;                                              ","arguments":[{"name":"KFOLD=","optional":true,"description":"specifies the number of partition folds in cross-validation, where n is an integer between 2 and the number of observations that are used for training, inclusive","help":"KFOLD=*n*","type":"value"},{"name":"STRATVAR=","optional":true,"description":"specifies a categorical variable for stratified cross-validation","help":"STRATVAR=*variable*","type":"value"}]},{"name":"INPUT","description":"specifies one or more predictor variables for the super learner model that share a common variable type","help":"INPUT  variables &lt;/option&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the variable type","help":"LEVEL=*value*","type":"value"}]},{"name":"MARGIN","description":"computes a predictive margin. You specify a unique name in single quotes, followed by one or more variable-value pairs that define the predictive margin.","help":"MARGIN  'name' variable='value' &lt;...variable='value'&gt;;                                              "},{"name":"OUTPUT","description":"creates a data table that contains observationwise predicted values that PROC SUPERLEARNER computes after fitting the model","help":"OUTPUT  OUT=*libref.data-table*&lt;options&gt;;                                              ","arguments":[{"name":"OUT=","optional":true,"description":"names the output data table for PROC SUPERLEARNER to use","help":"OUT=*libref.data-table*","type":"dataSet"},{"name":"COPYVAR=","optional":true,"aliases":["COPYVARS="],"description":"transfers one or more variables from the input data table to the output data table","help":"COPYVAR=*variable*","type":"value"},{"name":"LEARNERPRED","optional":true,"description":"computes predicted response values by using each trained base learner model","type":"standalone"},{"name":"MARGINPRED","optional":true,"description":"outputs the predicted response values under each intervening scenario that you specify in a MARGIN statement","type":"standalone"}]},{"name":"STORE","description":"saves the context and results of the statistical analysis","help":"STORE &lt;OUT=&gt;libref.data-table;                                              "},{"name":"TARGET","description":"specifies the response variable for the super learner model","help":"TARGET  variable &lt;/option&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the variable type","help":"LEVEL=*value*","type":"value"}]}],"supportSiteInformation":{"docsetId":"casstat","docsetVersion":"latest","docsetTargetFile":"casstat_superlearner_toc.htm"}}