{"name":"TABULARGAN","statements":[{"name":"PROC TABULARGAN","description":"The TABULARGAN procedure trains a correlation-preserving conditional tabular generative adversarial network (CPCTGAN) model on tabular data in SAS Viya. The procedure implements the CPCTGAN model by using the PyTorch library.","help":"PROC TABULARGAN <options>;                 \n\tAEOPTIMIZATION < ADAM(suboptions) ><options>;                 \n\tGANOPTIMIZATION < ADAM(suboptions) ><options>;                 \n\tGMM <options>;                 \n\tINPUT  variables </ LEVEL={INTERVAL | NOMINAL}>;                 \n\tOUTPUT  OUT=libref.data-table;                 \n\tSAVESTATE  RSTORE=libref.data-table;                 \n\tTRAIN <options>;                 ","arguments":[{"name":"DATA=","optional":true,"description":"names the input data table for PROC TABULARGAN to use","help":"DATA=*libref.data-table*","type":"dataSet"},{"name":"DETERMINISTIC","optional":true,"description":"DETERMINISTIC} tells the NVIDIA CUDA Deep Neural Network library (CuDNN) that you want only the deterministic implementations","type":"standalone"},{"name":"NUMSAMPLES=","optional":true,"description":"specifies the number of sample observations to generate","help":"NUMSAMPLES=*number*","type":"value"},{"name":"SCORESEED=","optional":true,"description":"specifies the seed to use for the random number generator for scoring","help":"SCORESEED=*number*","type":"value"},{"name":"SEED=","optional":true,"description":"specifies the seed to use for the random number generator for training","help":"SEED=*number*","type":"value"},{"name":"USEGPU","optional":true,"description":"specifies that a GPU device is to be used","help":"USEGPU(*suboptions*)","type":"value","arguments":[{"name":"DEVICE=","description":"specifies the ID number of the GPU device that is to be used","help":"DEVICE=*id-number*","type":"value"}]}]},{"name":"AEOPTIMIZATION","description":"specifies the optimizer parameters to use in training the autoencoder model","help":"AEOPTIMIZATION &lt; ADAM(*suboptions*) &gt;&lt;*options*&gt;;                                              ","arguments":[{"name":"ADAM","optional":true,"description":"specifies the optimization method to use in training the autoencoder model","help":"ADAM (BETA1=*number* BETA2=*number*)","type":"value","arguments":[{"name":"BETA1=","description":"specifies the exponential decay rate for the first-moment estimates","help":" BETA1=*number*","type":"value"},{"name":"BETA2=","description":"specifies the exponential decay rate for the second-moment estimates","help":" BETA2=*number*","type":"value"}]},{"name":"LEARNINGRATE=","optional":true,"description":"specifies the learning rate for the autoencoder's optimizer","help":" LEARNINGRATE=*number*","type":"value"},{"name":"NUMEPOCHS=","optional":true,"description":"specifies the number of epochs to use in training the autoencoder model","help":" NUMEPOCHS=*number*","type":"value"},{"name":"WEIGHTDECAY=","optional":true,"description":"specifies the weight decay for the autoencoder's optimizer","help":" WEIGHTDECAY=*number*","type":"value"}]},{"name":"GANOPTIMIZATION","description":"specifies the optimizer parameters to use in training the GAN model","help":"GANOPTIMIZATION &lt; ADAM(*suboptions*) &gt;&lt;*options*&gt;;                                              ","arguments":[{"name":"ADAM","optional":true,"description":"specifies the optimization method to use in training the GAN model","help":"ADAM (BETA1=*number* BETA2=*number*)","type":"value","arguments":[{"name":"BETA1=","description":"specifies the exponential decay rate for the first-moment estimates","help":" BETA1=*number*","type":"value"},{"name":"BETA2=","description":"specifies the exponential decay rate for the second-moment estimates","help":" BETA2=*number*","type":"value"}]},{"name":"LEARNINGRATE=","optional":true,"description":"specifies the learning rate for the optimizer","help":" LEARNINGRATE=*number*","type":"value"},{"name":"NUMEPOCHS=","optional":true,"description":"specifies the number of epochs to use in training the model GAN model","help":" NUMEPOCHS=*number*","type":"value"},{"name":"WEIGHTDECAYD=","optional":true,"description":"specifies the weight decay for the discriminator's optimizer","help":" WEIGHTDECAYD=*number*","type":"value"},{"name":"WEIGHTDECAYG=","optional":true,"description":"specifies the weight decay for the generator's optimizer","help":" WEIGHTDECAYG=*number*","type":"value"}]},{"name":"GMM","description":"specifies the Gaussian mixture model (GMM) parameters to be used to calculate the centroid information for the interval variables","help":"GMM &lt;options&gt;;                                              ","arguments":[{"name":"ALPHA=","optional":true,"description":"specifies the concentration parameter for the Dirichlet process","help":"ALPHA=*number*","type":"value"},{"name":"CENTROIDSTABLE=","optional":true,"description":"specifies the table that contains Gaussian mixture model (GMM) centroid information for continuous variables","help":"CENTROIDSTABLE=*libref.data-table*","type":"dataSet"},{"name":"MAXCLUSTERS=","optional":true,"description":"specifies the GMM maximum number of clusters","help":"MAXCLUSTERS=*number*","type":"value"},{"name":"SEED=","optional":true,"description":"specifies a value to use for starting the pseudorandom number generator for initialization","help":"SEED=*number*","type":"value"},{"name":"VB","optional":true,"description":"specifies the inference parameters for the variational Bayesian (VB) model","help":"VB(*suboptions*)","type":"value","arguments":[{"name":"COVARIANCE=","description":"specifies the GMM covariance matrix type","help":"COVARIANCE=DIAGONAL | FULL","type":"choice","arguments":[{"name":"DIAGONAL","description":"specifies the covariance matrices of the Gaussian distributions as diagonal matrices","type":"standalone"},{"name":"FULL","description":"specifies the covariance matrices of the Gaussian distributions as full matrices","type":"standalone"}]},{"name":"MAXVBITER=","description":"sets the maximum number of iterations for VB inference","help":"MAXVBITER=*number*","type":"value"},{"name":"THRESHOLD=","description":"specifies the GMM convergence threshold","help":"THRESHOLD=*number*","type":"value"}]}]},{"name":"INPUT","description":"names input variables that share a common option","help":"INPUT  variables &lt;/ LEVEL={INTERVAL | NOMINAL}&gt;;                                              ","arguments":[{"name":"LEVEL=","optional":true,"followsDelimiter":"/","description":"specifies the level of measurement of the variables","help":"LEVEL={INTERVAL | NOMINAL}","type":"choice"}]},{"name":"OUTPUT","description":"creates an output data table that contains the results of PROC TABULARGAN","help":"OUTPUT  OUT=*libref.data-table*;                                              ","arguments":[{"name":"OUT=","optional":true,"description":"specifies the output table in which to store the generated tabular data from the trained model","help":"OUT=*libref.data-table*","type":"dataSet"}]},{"name":"SAVESTATE","description":"creates an analytic store for the model and saves it as a binary object in a data table","help":"SAVESTATE  RSTORE=*libref.data-table*;                                              ","arguments":[{"name":"RSTORE=","description":"specifies a data table in which to save the analytic store for the model","help":"RSTORE=*libref.data-table*","type":"dataSet"}]},{"name":"TRAIN","description":"specifies the training parameters to use for training the tabular GAN model","help":"TRAIN &lt;options&gt;;                                              ","arguments":[{"name":"CHECKPOINTFREQ=","optional":true,"description":"specifies the frequency at which to save a checkpoint during training","help":"CHECKPOINTFREQ=*number*","type":"value"},{"name":"CHECKPOINTIN=","optional":true,"description":"specifies the checkpoint table to be loaded to restore your model","help":"CHECKPOINTIN=*libref.data-table*","type":"dataSet"},{"name":"CHECKPOINTOUT=","optional":true,"description":"specifies the table in which to save the current model as a checkpoint","help":"CHECKPOINTOUT=*libref.data-table*","type":"dataSet"},{"name":"EMBEDDINGDIM=","optional":true,"description":"specifies the dimensions of the input noise to the generator","help":"EMBEDDINGDIM=*number*","type":"value"},{"name":"MINIBATCHSIZE=","optional":true,"description":"specifies the number of observations in one minibatch","help":"MINIBATCHSIZE=*number*","type":"value"},{"name":"PACKSIZE=","optional":true,"description":"specifies the number of samples to group together in applying the discriminator","help":"PACKSIZE=*number*","type":"value"},{"name":"PRINTFREQ=","optional":true,"description":"specifies the frequency at which to print losses to the log and the iteration history table","help":"PRINTFREQ=*number*","type":"value"},{"name":"REGR1WEIGHT=","optional":true,"description":"specifies the weight to use in regularizing the discriminator","help":"REGR1WEIGHT=*number*","type":"value"},{"name":"USEORIGLEVELFREQ","optional":true,"description":"USEORIGLEVELFREQ} uses the log-frequency of categorical levels in the conditional sampling","type":"standalone"}]}],"supportSiteInformation":{"docsetId":"casml","docsetVersion":"latest","docsetTargetFile":"casml_tabulargan_toc.htm"}}